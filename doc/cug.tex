\section{Introduction: How Cylc Works} 
\label{HowCylcWorks}

\subsection{Scheduling Forecast Suites} 
\label{SchedulingForecastSuites}

Environmental forecasting suites generate forecast products from a
potentially large group of interdependent scientific models and
associated data processing tasks. They are constrained by availability
of external driving data: typically one or more tasks will wait on real
time observations and/or model data from an external system, and these
will drive other downstream tasks, and so on. The dependency diagram for
a single forecast cycle in such a system is a {\em Directed Acyclic
Graph} as shown in Figure~\ref{fig-dep-one} (in our terminology, a {\em
forecast cycle} is comprised of all tasks with a common {\em cycle
time}, which is the nominal analysis time or start time of the forecast
models in the group). In real time operation processing will consist of
a series of distinct forecast cycles that are each initiated, after a
gap, by arrival of the new cycle's external driving data.

From a job scheduling perspective task execution order in such a system
must be carefully controlled in order to avoid dependency violations.
Ideally, each task should be queued for execution at the instant its
last prerequisite is satisfied; this is the best that can be done even
if queued tasks are not able to execute immediately because of resource
contention.

\subsection{EcoConnect} 
\label{EcoConnect}

Cylc was developed for the EcoConnect Forecasting System at NIWA
(National Institute of Water and Atmospheric Research, New Zealand).
EcoConnect takes real time atmospheric and stream flow observations, and
operational global weather forecasts from the Met Office (UK), and uses
these to drive global sea state and regional data assimilating weather
models, which in turn drive regional sea state, storm surge, and
catchment river models, plus tide prediction, and a large number of
associated data collection, quality control, preprocessing,
postprocessing, product generation, and archiving tasks.\footnote{Future
plans for EcoConnect include additional deterministic regional weather
forecasts and a statistical ensemble.} The global sea state forecast
runs once daily. The regional weather forecast runs four times daily but
it supplies surface winds and pressure to several downstream models that
run only twice daily, and precipitation accumulations to catchment river
models that run on an hourly cycle assimilating real time stream flow
observations and using the most recently available regional weather
forecast.  EcoConnect runs on heterogenous distributed hardware,
including a massively parallel supercomputer and several Linux servers. 


\subsection{Dependencies Between Tasks}

\subsubsection{Intracycle Dependencies} 
\label{IntracycleDependencies}

Most inter-task dependencies exist within a single forecast cycle.
Figure~\ref{fig-dep-one} shows the dependency diagram for a single
forecast cycle of a simple example suite of three forecast models ({\em
a, b,} and {\em c}) and three post processing or product generation
tasks ({\em d, e} and {\em f}). A scheduler capable of handling this
must manage, within a single forecast cycle, multiple parallel streams
of execution that branch when one task generates output for several
downstream tasks, and merge when one task takes input from several
upstream tasks. 

\begin{figure}
    \begin{center}
        \includegraphics[width=6cm]{images/dep-one-cycle.png} 
    \end{center}
    \caption[A single cycle dependency graph for a simple suite]{\small
    The dependency graph for a single forecast cycle of a simple example
    suite. Tasks {\em a, b,} and {\em c} represent forecast models,
    {\em d, e} and {\em f} are post processing or product generation
    tasks, and {\em x} represents external data that the upstream
    forecast model depends on.}
    \label{fig-dep-one} 
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=8cm]{images/timeline-one.png}
    \end{center}
    \caption[A single cycle job schedule for real time operation]{\small
    The optimal job schedule for two consecutive cycles of our example
    suite during real time operation, assuming that all tasks trigger 
    off upstream tasks finishing completely. The horizontal extent of
    a task bar represents its execution time, and the vertical blue
    lines show when the external driving data becomes available.}
    \label{fig-time-one}
\end{figure}

Figure~\ref{fig-time-one} shows the optimal job schedule for two
consecutive cycles of the example suite in real time operation, given
execution times represented by the horizontal extent of the task bars.
There is a time gap between cycles as the suite waits on new external
driving data.  Each task in the example suite happens to trigger off
upstream tasks {\em finishing}, rather than off any intermediate output
or event; this is merely a simplification that makes for clearer
diagrams.

\begin{figure}
    \begin{center}
        \includegraphics[width=10cm]{images/dep-two-cycles-linked.png} 
    \end{center}
    \caption[What if the external driving data is available early?]{\small If
    the external driving data is available in advance, can we start
    running the next cycle early?} 
    \label{fig-dep-two-linked}
\end{figure}

\begin{figure}
    \begin{center}
        \includegraphics[width=6cm]{images/timeline-one-c.png} 
    \end{center}
    \caption[Attempted overlap of consective single-cycle job
    schedules]{\small A naive attempt to overlap two consecutive cycles
    using the single-cycle dependency graph. The red shaded tasks will
    fail because of dependency violations (or will not be able to run
    because of upstream dependency violations).} 
    \label{fig-overlap}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=8cm]{images/timeline-one-a.png} 
    \end{center}
    \caption[The only safe multicycle job schedule?]{\small The best that
    can be done {\em in general} when intercycle dependencies are
    ignored.} 
    \label{fig-job-no-overlap}
\end{figure} 

Now the question arises, what happens if the external driving data for
upcoming cycles is available in advance, as it would be after a
significant delay in operations, or when running a historical case
study?  While the forecast model {\em a} appears to depend only on the
external data {\em x} at this stage of the discussion, in fact it would 
typically also depend on its own previous instance for the model {\em
background state} used in initializing the new forecast. Thus, as
alluded to in Figure~\ref{fig-dep-two-linked}, task {\em a} could in
principle start
as soon as its predecessor has finished.  Figure~\ref{fig-overlap}
shows, however, that starting a whole new cycle at this point is
dangerous - it results in dependency violations in half of the tasks in
the example suite. In fact the situation is even worse than this
- imagine that task {\em b} in the first cycle is delayed for any reason
{\em after} the second cycle has been launched? Clearly we must consider
handling intercycle dependencies explicitly or else agree not to start
the next cycle early, as is illustrated in Figure~\ref{fig-job-no-overlap}.

\subsubsection{Intercycle Dependencies} 
\label{IntercycleDependencies}

In most suites dependencies between tasks in different cycles
exist. Forecast models, as above, typically depend on their own most
recent previous forecast for a background state, and different
types of tasks in different forecast cycles can also be linked (in an 
atmospheric forecast analysis suite, for instance, the weather model 
may also generate background states for use by the observation
processing and data-assimilation systems in the next cycle). In real
time operation these intercycle dependencies
can be ignored because they are automatically satisfied when each cycle
finishes before the next one begins. This is just as well
because they dramatically increase the complexity of the dependency
graph of even the simplest suites, by destroying the clean boundary
between forecast cycles. Figure~\ref{fig-dep-multi} illustrates the
problem for our simple example suite assuming the minimal likely
intercycle dependence: the forecast models ($a$, $b$, and $c$) each
depend on their own previous instances.

For this reason, and because we tend to imagine that forecasting suites
always run in distinct cycles, existing metaschedulers (as far as the author
is aware!) ignore intercycle dependencies and therefore {\em require} a
series of distinct cycles at all times. While this does not affect
normal real time operation it can be a serious impediment when advance
availability of external driving data makes it possible, in principle,
to run some tasks from upcoming cycles before the current cycle is
finished - as suggested at the end of the previous section. This occurs
after delays (late arrival of external data, system maintenance, etc.)
and, to an even greater extent, in historical case studies, and parallel
test suites that are delayed with respect to the main operation. It is
a serious problem, in particular, for suites that have little downtime
between forecast cycles and therefore take many cycles to catch up
after a delay. Without taking account of intercycle dependencies, the
best that can be done, in general, is to reduce the gap between cycles
to zero as shown in Figure~\ref{fig-job-no-overlap}. A limited crude
overlap of the single cycle job schedule may be possible for specific
task sets but the allowable overlap may change if new tasks are added,
and it is still dangerous: it amounts to running different parts of a
dependent system as if they were not dependent and as such it cannot be
guaranteed that some unforeseen delay in one cycle, after the 
next cycle has begun, (e.g.\ due to resource contention or task
failures) won't result in dependency violations.

\begin{figure}
    \begin{center}
        \includegraphics[width=8cm]{images/dep-multi-cycle.png} 
    \end{center}
    \caption[The complete multicycle dependency graph]{\small The complete
    dependency graph for the example suite, assuming the least possible
    intercycle dependence: the forecast models ($a$, $b$, and $c$)
    depend on their own previous instances. The dashed arrows show
    connections to previous and subsequent forecast cycles.} 
    \label{fig-dep-multi}
\end{figure}

\begin{figure}
    \begin{center}
        \includegraphics[width=6cm]{images/timeline-two-cycles-optimal.png} 
    \end{center}
    \caption[The optimal two-cycle job schedule]{\small The optimal two
    cycle job schedule when the next cycle's driving data is available in
    advance, possible in principle when intercycle dependencies are
    handled explicitly.} 
    \label{fig-optimal-two}
\end{figure} 

Figure~\ref{fig-optimal-two} shows, in contrast to
Figure~\ref{fig-overlap}, the optimal two cycle job schedule obtained by
respecting all intercycle dependencies.  This assumes no delays due to
resource contention or otherwise - i.e.\ every task runs
as soon as it is ready to run. The scheduler running
this suite must be able to adapt dynamically to external conditions 
that impact on multicycle scheduling in the presence of
intercycle dependencies or else, again, risk bringing the system down
with dependency violations.

\begin{figure}
    \begin{center}
        \includegraphics[width=12cm]{images/timeline-three.png} 
    \end{center}
    \caption[Comparison of job schedules after a delay]{\small Job
    schedules for the example suite after a delay of almost one whole
    forecast cycle, when intercycle dependencies are
    taken into account (above the time axis), and when they are not
    (below the time axis). The colored lines indicate the time that
    each cycle is delayed, and normal ``caught up'' cycles
    are shaded gray.} 
    \label{fig-time-three}
\end{figure} 

\begin{figure}
    \begin{center} 
        \includegraphics[width=8cm]{images/timeline-two.png}
    \end{center} 
    \caption[Optimal job schedule when all external data is
    available]{\small Job schedules for the example suite in case study
    mode, or after a long delay, when the external driving data are
    available many cycles in advance. Above the time axis is the optimal
    schedule obtained when the suite is constrained only by its true
    dependencies, as in Figure \ref{fig-dep-two-linked}, and underneath
    is the best that can be done, in general, when intercycle
    dependencies are ignored.} 
    \label{fig-time-two}
\end{figure} 

To further illustrate the potential benefits of proper intercycle
dependency handling, Figure~\ref{fig-time-three} shows an operational
delay of almost one whole cycle in a suite with little downtime between
cycles. Above the time axis is the optimal schedule that is possible, in
principle, when intercycle dependencies are taken into account, and
below is the only safe schedule possible {\em in general} when they are
ignored.  In the former case, even the cycle immediately after the delay
is hardly affected, and subsequent cycles are all on time, whilst in the
latter case it takes five full cycles to catch up to normal real time
operation.
%Note that simply overlapping the single cycle schedules of
%Figure~\ref{fig-time-one} from the same start point would have resulted
%in dependency violation by task {\em c}.

Similarly, Figure~\ref{fig-time-two} shows example suite job schedules
for an historical case study, or when catching up after a very long
delay; i.e.\ when the external driving data are available many cycles in
advance.  Task {\em a}, which as the most upstream forecast model is
likely to be a resource intensive atmosphere or ocean model, has no
upstream dependence on cotemporal tasks and can therefore run
continuously, regardless of how much downstream processing is yet to be
completed in its own, or any previous, forecast cycle (actually, task
{\em a} does depend on cotemporal task {\em x} which waits on the
external driving data, but that returns immediately when the external
data is available in advance, so the result stands). The other forecast
models can also cycle continuously or with short gap between, and some
post processing tasks, which have no previous-instance dependence, can
run continuously or even overlap (e.g.\ {\em e} in this case). Thus,
even for this very simple example suite, tasks from three or four
different cycles can in principle run simultaneously at any given time. 
In fact, if our tasks are able to trigger off internal outputs of 
upstream tasks, rather than waiting on full completion, successive
instances of the forecast models could overlap as well (because model
restart outputs are generally completed early in the forecast) for an
even more efficient job schedule. 

%Finally, we note again that a good job scheduler should be able to
%dynamically adapt to delays in any part of the suite due to resource
%contention, varying run times, or anything else that will inevitably
%modify the depicted job schedules. 

\subsection{The Cylc Scheduling Algorithm} 
\label{TheCylcSchedulingAlgorithm}

\begin{figure}
    \begin{center} 
        \includegraphics[width=8cm]{images/task-pool.png}
    \end{center} 
    \caption[The cylc task pool]{\small How cylc sees a suite, in
    contrast to the multicycle dependency graph of Figure~\ref{fig-dep-multi}.
    Task colors represent different cycle times, and the small squares
    and circles represent different prerequisites and outputs. A task
    can run when its prerequisites are satisfied by the outputs 
    of other tasks in the pool.} 
    \label{fig-task-pool}
\end{figure} 

Cylc manages a pool of proxy objects that represent real tasks in the
forecasting suite. A task proxy can run the real task that it
represents when its prerequisites are satisfied, and can receive reports
of completed outputs from the real task as it runs. There is no global
cycling mechanism to advance the suite in time; instead each individual
task proxy has a private cycle time and spawns its own successor. Task
proxies are self-contained - they just know their own prerequisites and
outputs and are not aware of the wider suite context. Intercycle
dependencies are not treated as special, and the task pool can be
populated with tasks from many different cycle times. 
The cylc task pool is illustrated in Figure~\ref{fig-task-pool}. Now,
{\em whenever any task changes state
due to completion of an output, every task checks to see if its
own prerequisites are now satisfied.}\footnote{In fact this dependency
negotiation goes through a broker object (rather than every task
literally checking every other task) which scales as $n$ (rather than
$n^2$) where $n$ is the number of task proxies in the pool.}  Moreover,
this matching of prerequisites and outputs involves the entire task
pool, regardless of individual cycle times, so that inter- and
intra-cycle dependencies are handled with ease.

Thus without using global cycling mechanisms, and treating all
dependencies equally, cylc in effect gets a pool of tasks to
self-organise by negotiating their own dependencies so that optimal
scheduling, as described in the previous section, emerges naturally at
run time.

%Perhaps the most difficult problem encountered during cylc
%implementation was how to arrange that every task proxy object exists by
%the time it is needed, but not too much earlier, and does not die too
%long after it is no longer needed. This engendered no small amount
%of hair pulling and teeth gnashing, but once achieved the complexities
%therein are entirely hidden from the user.

%\pagebreak
\section{Installation} 

\subsection{Requirements} 
\label{Requirements}

\begin{myitemize}
    \item Operating System: Linux or Unix \footnote{The cylc codebase
        assumes Unix-style file paths in places, but it could easily
        made more portable if necessary.} 
    \item Python Version: 2.4 or later, but not Python
        3.x as yet.\footnote{Python 2.4 was released in November 2004. Python 3
        is the future of Python, but it is not backward compatible with
        2.x and consequently still has significantly less library and
        third party support.  As of mid 2011, Python 2.7 is still the
        standard for new Linux distributions.}
    \item PyGTK, a Python wrapper for the GTK+ graphical user interface toolkit.
        PyGTK is included in most Linux Distributions. \newline
        {\em http://www.pygtk.org}
    \item Pyro 3 (Python Remote Objects) - latest version test
        3.14.\footnote{As of April 2011, Pyro 4, which is compatible
        with Python 3, is in development but it is still not recommended
        for production use.} \newline
        {\em http://www.xs4all.nl/~irmen/pyro3}
    \item The graphviz graph layout engine (latest version tested:
        2.28.0). \newline
        {\em http://www.graphviz.org}
    \item Pygraphviz, a python interface to graphviz (latest version
        tested: 1.1).  \newline
        {\em http://networkx.lanl.gov/pygraphviz}
\end{myitemize}

Python and Pyro are essential. PyGTK is required by the gcylc GUI
(but you can control and monitor cylc suites from the command line). 
Graphviz and pygraphviz are required for dependency graphing and the
graph-based suite control GUI (but you can also run cylc without them).

Cylc has absorbed the following software in modified form (no need to
install them): 
\begin{myitemize}
    \item xdot, a graph viewer
        (http://code.google.com/p/jrfonseca/wiki/XDot,
        LGPL license)
    \item ConfigObj and Validate 
        (http://www.voidspace.org.uk/python, %configobj.html,
        BSD license)

\end{myitemize}

\subsection{Unpacking The Cylc Tarball}
\label{UnpackingTheCylcTarball}

Cylc installs into a normal user account; just unpack the release
tarball in the desired location.

\subsection{Configuring Your Environment For Cylc}

To gain access to cylc type the following at the command prompt:
\begin{lstlisting}
$ export CYLC_DIR=/path/to/cylc/installation/
$ . $CYLC_DIR/environment.sh
\end{lstlisting}
Put this into your \lstinline=.profile= login script to configure
cylc access automatically. The variable \lstinline=$CYLC_DIR=
is required inside the environment script, so don't skip the export
step.  You should now be able to run cylc commands:
\begin{lstlisting}
$ cylc --version
3.x.y
\end{lstlisting}

% TO DO: SYSTEM LEVEL INSTALL INSTRUCTIONS
%For a system-level install just inspect the environment script for the
%few critical executable and source module paths, and install the
%contents therein in standard system locations. Users would then not need
%to source the environment script before using cylc. 

%\subsubsection{Other}
%
%Pyro, graphviz, and Pygraphviz all have their own simple installation
%instructions.  If you can't get these installed at system level it is 
%quite possible to install them all into a user account, and then adapt
%the cylc environment script slightly to ensure that cylc can access 
%them.

\subsection{Creating The Central Suite Database}
\label{CreatingTheCentralSuiteDatabase}

Cylc has a central suite database, visible to all users on the 
cylc host, to facilitate sharing of suites. Run the following 
command immediately after installation to create the central database
and export several example suites to it:

\begin{lstlisting}
$ cylc admin create-cdb
\end{lstlisting}

To view the content of the resulting central database, run gcylc and
switch to the central database using the Database menu, or 
use \lstinline=cylc db print --central= on the command line.

%\lstset{ basicstyle=\color{basic}\scriptsize\ttfamily }
\begin{lstlisting}
$ cylc db print --central
 admin:examples:CUG1    "Cylc User Guide Example 1"  ~admin/cylc/examples/CUG1
 admin:examples:CUG73   "Cylc User Guide <SNIP>"     ~admin/cylc/examples/CUG7.3
 admin:examples:CUG74   "A two-task test suite"      ~admin/cylc/examples/CUG7.4
 admin:examples:CUG_QS1 "Cylc User Guide <SNIP> "    ~/dmin/cylc/examples/CUG5/one
 admin:examples:CUG_QS2 "Cylc User Guide <SNIP>"     ~admin/cylc/examples/CUG5/two
 admin:examples:CUG_QS3 "Cylc User Guide <SNIP>"     ~admin/cylc/examples/CUG5/three
 admin:examples:FFHook  "family failure hook <SNIP>" ~admin/cylc/examples/<SNIP>
 admin:examples:FFTask  "family failure clean <SNIP>"~admin/cylc/examples/<SNIP>
DONE
\end{lstlisting}
%\lstset{ basicstyle=\color{basic}\footnotesize\ttfamily }
(some strings above have been truncated to reduce the line length)

\subsection{Running The Automated Database Test} 
\label{RTADT}

\lstset{language=bash}
The command \lstinline=cylc admin test-db= gives suite database
functionality a work out - it registers the User Guide example suite
under a new name and then manipulates it (by copying the suite in
various ways, exporting it to the central database, and so on, before
finally deleting the test registrations). This process should complete
without error in a few seconds.

\subsection{Running The Automated Scheduler Test} 
\label{RTAST}

The command \lstinline=cylc admin test-suite= tests the cylc scheduler
itself by running a suite registered as {\em examples:test} in the 
central database (by \lstinline=cylc admin create-cdb=, above)
configuring it to fail out a specific task, and then doing some advanced
failure recovery intervention on it (recursive purge plus insertion of
cold start tasks).
This process should complete in 2-3 minutes and can be watched in real
time by right-clicking on the temporary test suite when it appears in
the gcylc private database window, and opening up a suite control GUI.

This test is aimed only at scheduling functionality so the test suite 
is configured not to use the cylc lockserver (see {\em Starting Your 
Lockserver Daemon}, Section~\ref{StartingYourLockserverDaemon}).

{\em The test-suite command does not currently detect failure of the
running suite, it will just keep waiting. To see if this has happened
(it shouldn't!) take a look at the file \lstinline=test-suite.out= 
that is generated by the test-suite script.} This will be addressed in a
future cylc release.

\subsection{Installing Everything Under Your Home Directory}

If you do not have root access to your host machine and cannot easily
get Pyro, Graphviz, and Pygraphviz installed at system level, here's
how to install everything under your home directory. 

\subsubsection{Cylc}

Cylc is already designed to be installed into a normal user account -
just unpack the cylc release tarball in the desired location, which 
we shall refer to below as \lstinline=$CYLC_DIR=.

If you try to use cylc commands now you will get a warning that Pyro is
not installed.

\subsubsection{Download Pyro, Graphviz, And Pygraphviz}

Create a new sub-directory in the cylc source tree,
\lstinline=$CYLC_DIR/external=, and download the Pyro,
Graphviz, and Pygraphviz source distributions to it (from the URLs given
at the beginning of Section~\ref{Requirements}).

\subsubsection{Pyro}

Install Pyro under \lstinline=$CYLC_DIR/external/installed= as follows:
\begin{lstlisting}
$ cd $CYLC_DIR/external
$ tar xzf Pyro-3.14.tar.gz
$ cd Pyro-3.14
$ python setup.py install --prefix=$CYLC_DIR/external/installed
\end{lstlisting}
Take note of the resulting Python \lstinline=site-packages= directory
under \lstinline=external/installed/=, e.g.:
\begin{lstlisting}
$CYLC_DIR/external/installed/lib64/python2.6/site-packages/
\end{lstlisting}
(The exact path will depend on your local Python environment).
Add this to your \lstinline=PYTHONPATH= by editing 
\lstinline=$CYLC_DIR/environment.sh=, uncommenting the paragraph 
that begins with:
\begin{lstlisting}
# FOR LOCAL INSTALLATION OF PYRO, GRAPHVIZ, AND PYGRAPHVIZ
\end{lstlisting}
and altering the paths under it to suit your local installation. 

Now you should be able to source the cylc environment and get cylc
to print its release version: 
\begin{lstlisting}
$ export CYLC_DIR=$HOME/cylc-3.3.3   # or whichever version you have    
$ . $CYLC_DIR environment.sh
CONFIGURING THIS SHELL FOR /wdata/hilary/cylc-3.3.3/bin/cylc
Cylc release version: 3.3.3
$ cylc -v
3.3.3
\end{lstlisting}
If this command aborts and says that Pyro is not installed or is not available,
then you have either not installed Pyro (check the output of the installation 
command carefully) {\em or} you have not pointed to the installed Pyro modules
in your PYTHONPATH, {\em or} you have not sourced the cylc environment script 
since updating its PYTHONPATH.

\subsubsection{Create The Suite Database And Load The Example Suites}

Now create the suite database and upload the example suites as described
in Section~\ref{CreatingTheCentralSuiteDatabase}.  At this point you 
should have access to all cylc functionality except for suite graphing
and the graph based suite control GUI. 

\subsubsection{Graphviz}

Install Graphviz under \lstinline=$CYLC_DIR/external/installed= as
follows:
\begin{lstlisting}
$ cd $CYLC_DIR/external
$ tar xzf graphviz-2.28.0.tar.gz
$ cd graphviz-2.28.0
$ ./configure --prefix=$CYLC_DIR/external/installed
$ make
$ make install
\end{lstlisting}
This installs graphviz files into the bin, include, and lib
sub-directories of your local installation directory. The local
installation section of your cylc environment script (above) provides
access to the graphviz executables in this bin directory, although you
will probably not need to use them. The graphviz lib and include
locations are required when installing Pygraphviz (next).

{\em Note that graphviz may fail to build on a system that does not 
have QT installed}. Lack of QT is not important for our purposes and 
you can disable it with \lstinline=./configure --with-qt=no=.

\subsubsection{Pygraphviz}

Install Pygraphviz under \lstinline=$CYLC_DIR/external/installed= as
follows:
\begin{lstlisting}
$ cd $CYLC_DIR/external
$ tar xzf pygraphviz-1.1.tar.gz
$ cd pygraphviz-1.1
\end{lstlisting}
Now edit setup.py lines 31 and 32 to specify the graphviz lib and
include directories:
\begin{lstlisting}
library_path=os.environ['CYLC_DIR'] + '/external/installed/lib'
include_path=os.environ['CYLC_DIR'] + '/external/installed/include/graphviz'
\end{lstlisting}
Or you can just specify the absolute paths if you like, instead of using
the \lstinline=$CYLC_DIR= environment variable. Check that these are the
correct library and include paths by inspecting the contents of the
specified directories, and adjust them if necessary.  Finally, install
pygraphviz:
\begin{lstlisting}
$ export CYLC_DIR=/path/to/cylc  # (if not done already)
$ python setup.py install --prefix=$CYLC_DIR/external/installed
\end{lstlisting}
This may or may not, depending on your local Python setup, install the
Pygraphviz modules into the same place as the Pyro modules, e.g.:
\begin{lstlisting}
$ ls $CYLC_DIR/external/installed/lib64/python2.6/site-packages/
 pygraphviz  pygraphviz-1.1-py2.6.egg-info  Pyro  Pyro-3.14-py2.6.egg-info
\end{lstlisting}
If not, add the correct Pyraphviz installation path to the
PYTHONPATH variable in your cylc environment script.

The easiest way to check that pygraphviz has been installed properly is
to start an interactive Python session (type {\em python} after
sourcing the cylc environment script to configure your PYTHONPATH) then
type {\em import pygraphviz} at the python interpreter prompt. If this
results in the error message
{\em ImportError: No module named pygraphviz} then either you have 
not installed pygraphviz properly, {\em or} you have not configured your
PYTHONPATH to point to the installed pygraphviz modules, {\em or} you have not
sourced the cylc environment script since updating its PYTHONPATH.
Finally, if you have installed pygraphviz and configured your PYTHONPATH
properly but graphviz itself has not been installed properly (or if the
graphviz libraries have been deleted since you installed pygraphviz)
then the initial pygraphiz import will be successful but a lower level
import will fail when the pygraphviz modules cannot load the underlying
graphviz libraries - in that case, reinstall graphviz.

\subsubsection{What Next?}

You should now have access to all cylc functionality.  Create 
the central suite database and upload the example suites now, if 
you have not done so already
(Section~\ref{CreatingTheCentralSuiteDatabase}), then test 
your cylc installation by running the automated suite database test
(Section~\ref{RTADT}) and the automated scheduler test
(Section~\ref{RTAST}), and go on to the {\em Quick Start Guide}
(Section~\ref{QuickStartGuide}).

\subsection{Upgrading To A New Cylc Version}

This is as simple as unpacking the new cylc release and replacing the 
old example suites with the new ones in the central suite database. 

In a future release we will make the central suite database 
installation-independent.  Currently though it is held in the cylc
installation directory under \lstinline=$CYLC_DIR/CDB=, i.e. if you have
multiple versions of cylc on the one host each will have its own
central database. The following procedure takes the old central database
over to a new installation, replacing the old example suites in it with
the new ones:

\begin{myenumerate}
    \item Before upgrading (under the old cylc version), unregister the
        {\em examples} group from the central suite database. 
    \item Download the new cylc release tarball and unpack it.
    \item Copy (via the shell) the central database from the old
        installation to the new.
    \item Source the new cylc environment script.
    \item Run \lstinline=cylc admin create-cdb= to upload the example
        suites for the new release.
\end{myenumerate}


%\pagebreak
\section{Cylc Screenshots}

The following screenshots provide a glimpse of what the cylc user
interface looks like.

\begin{myitemize}
    \item Figure~\ref{fig-command-help} - the cylc command line interface.
    \item Figure~\ref{fig-db} - viewing a private suite database in gcylc.
    \item Figure~\ref{fig-cdb} - viewing the central suite database in gcylc.
    \item Figure~\ref{fig-cylc-vim} - a cylc suite definition file (suite.rc) in the vim editor.
    \item Figure~\ref{fig-simple-graph-2} - the suite definition of Figure~\ref{fig-cylc-vim} graphed by cylc.
    \item Figure~\ref{fig-gcylc-treeview} - suite control GUI, treeview interface.
    \item Figure~\ref{fig-gcylc-graph} - suite control GUI, graph-based interface.
    \item Figure~\ref{fig-ecox-1} - a large operational suite graphed by cylc.
    \item Figure~\ref{fig-ecox-2} - another view of the large operational suite of Figure~\ref{fig-ecox-1}.
\end{myitemize}

\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{screenshots/commandhelp.png}
    \end{center}
\caption[\small The cylc command line interface]{The cylc command line interface}
\label{fig-command-help}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{screenshots/db.png}
    \end{center}
\caption[gcylc showing a private suite database]{\small
gcylc showing a private suite database.}
\label{fig-db}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{screenshots/cdb.png}
    \end{center}
\caption[gcylc showing the central suite database]{\small
gcylc showing the central suite database.}
\label{fig-cdb}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[height=0.45\textheight]{screenshots/simple-suiterc.png}]
    \end{center}
    \caption[A simple cylc suite definition edited in {\em vim}]{\small
    A simple cylc suite definition edited in {\em vim}}
    \label{fig-cylc-vim} 
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.35\textheight]{screenshots/simple-18-cold.png}
    \end{center}
    \caption[The suite definition of Figure~\ref{fig-cylc-vim} graphed
    by cylc.]{\small The suite definition of Figure~\ref{fig-cylc-vim}
    graphed by cylc.}
\label{fig-simple-graph-2}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{screenshots/control-trad.png}
    \end{center}
\caption[The suite control GUI, treeview interface.]{\small The suite
control GUI, treeview interface.}
\label{fig-gcylc-treeview}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{screenshots/control-graph.png}
    \end{center}
\caption[The suite control GUI, graph interface.]{\small The suite control GUI, graph interface.}
\label{fig-gcylc-graph}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=\textwidth]{screenshots/ecox-1.png}
    \end{center}
\caption[A large operational suite graphed by cylc.]{\small A large
operational suite graphed by cylc.}
\label{fig-ecox-1}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{screenshots/ecox-2.png}
    \end{center}
    \caption[Another view of the large operational suite of
    Figure~\ref{fig-ecox-1}]{\small Another view of the large
    operational suite of Figure~\ref{fig-ecox-1}.}
\label{fig-ecox-2}
\end{figure} 


% dump floats
\clearpage

%\pagebreak

\section{On The Meaning Of {\em Cycle Time} In Cylc}

%You may be used to the idea that a forecasting suite has a ``current
%cycle time'', which is the analysis time or nominal start time
%associated with the main forecast model(s) in the suite, and that
%the whole suite advances to the next forecast cycle when all tasks in
%the current cycle have finished (or even when a particular wall clock
%time is reached, in real time operation). This is not how cylc works.

As explained in {\em Introduction: How Cylc Works}
(Section~\ref{HowCylcWorks}): {\bf cylc has no concept of global cycle
time}.  Instead, {\bf each task has its own private cycle time} and can
run when its prerequisites are satisfied regardless of other tasks with
different cycle times running at the same time. {\bf Cylc suites advance
by means of each task spawning a successor at the next valid cycle time
for the task}, not by incrementing a suite-wide forecast cycle. 

However, it may still be convenient sometimes to refer to the ``current
cycle'', the ``previous cycle'', or the ``next cycle'' and so forth,
with reference to a particular task, or in the sense of all tasks that
``belong to'' a particular forecast cycle.  Just keep in mind that the
members of such a group may not all exist in the running suite at the
same time. In other words, some tasks may pass through the ``current cycle''
(etc.) at different times as the suite evolves, particularly in delayed
(catch up) operation.

\section{Quick Start Guide} 
\label{QuickStartGuide}

\lstset{language=bash}

This section works through some basic cylc functionality using
the ``QuickStart'' example suites, which should have been registered in
the central suite database during cylc installation, 

%\lstset{ basicstyle=\color{basic}\scriptsize\ttfamily }
\begin{lstlisting}
$ cylc database print --central | grep Quick
 admin:examples:CUG_QS1 "<SNIP>Quick Start Example 1" ~admin/cylc/examples/CUG5/one
 admin:examples:CUG_QS2 "<SNIP>Quick Start Example 2" ~admin/cylc/examples/CUG5/two
 admin:examples:CUG_QS3 "<SNIP>Quick Start Example 3" ~admin/cylc/examples/CUG5/three
DONE
\end{lstlisting}
%\lstset{ basicstyle=\color{basic}\footnotesize\ttfamily }
(suite titles have been truncated above to reduce line length).

\subsection{Configuring Your Environment For Cylc}

To gain access to cylc you just need to source the cylc environment
script. Put the following code in your login script, or do the same at the
terminal prompt before using cylc.\footnote{To switch between different
cylc installations just source the appropriate environment script.}
\begin{lstlisting}
# .profile
export CYLC_DIR=/path/to/cylc/installation
. $CYLC_DIR/environment.sh
\end{lstlisting}
The variable \lstinline=$CYLC_DIR= is required inside the environment
script, so don't skip the export step. You should now be able to run
cylc commands:
\begin{lstlisting}
$ cylc --version
3.x.y
\end{lstlisting}

You should also specify the graphical and terminal editors you want to
use to edit suites, by setting the following environment variables in
your \lstinline=.profile=:
\begin{lstlisting}
# .profile
export GEDITOR='gvim -f'  # GUI editor launched by gcylc
export EDITOR=vim         # terminal editor launched by 'cylc edit'
\end{lstlisting}
See \lstinline=cylc edit help= (Appendix~\ref{edit}) for other editor
examples. And finally, you must ensure that \lstinline=$TMPDIR= is 
defined in your environment, for example:
\begin{lstlisting}
# .profile
export TMPDIR=/tmp/$USER
\end{lstlisting}

\subsection{Starting Your Lockserver Daemon}
\label{StartingYourLockserverDaemon}


Each cylc user should run a lockserver to prevent accidental 
invocation of multiple instances of the same suite or task at the same 
time.  The suite and task locks brokered by the lockserver are analogous
to traditional lock files, but they work across a network, even for
distributed suites containing tasks that start executing on one host and
finish on another.

The lockserver daemon can be started at any time and left running.
\begin{lstlisting}
$ cylc lockserver start
\end{lstlisting}

Check that it is running,
\begin{lstlisting}
$ cylc lockserver status
\end{lstlisting}

For detailed usage information,
\begin{lstlisting}
$ cylc lockserver --help 
\end{lstlisting}

There is a command line client interface, 
\lstinline=cylc lockclient=,
for interrogating the lockserver and managing 
locks manually (e.g.\ releasing locks if a suite was killed 
before it could clean up after itself).

You can also choose not to use the lockserver for a particular suite, by
setting the following switch in its suite.rc (suite definition) file,
\begin{lstlisting}
# SUITE.RC:
use lockserver = False  # not recommended!
\end{lstlisting}

\subsection{Starting The gcylc GUI}

At the command prompt:
\begin{lstlisting}
$ gcylc &
\end{lstlisting}
and use the Database menu to switch to the central database, which
displays suites accessible to all users, in a treeview organized by
owner, group, and name (see Figure~\ref{fig-cdb}).

\subsubsection{Central Suite Database Actions}

By right-clicking on a suite in the central database, or using the cylc
command line, you can:
\begin{myenumerate}
    \item retrieve the suite description,
    \item list tasks in the suite,
    \item view the suite definition in your editor,
    \item plot the suite dependency graph,
    \item search the suite definition and bin scripts,
    \item validate the suite definition,
    \item compare (difference) the suite with another suite,
    \item import the suite or group to your private database,
    \item unreregister or delete the suite or group (if you own it),
    \item reregister the suite or group (if you own it).
\end{myenumerate}
But you can only {\em run} suites that are registered in your private
database. 

\subsection{Importing The QuickStart Suites To Your Private Database} 

You can register new suites directly in your private database using gcylc 
or \lstinline=cylc db register=, or you can import suites
from the central database.

Find the suites registered under the {\em admin:examples} group in the
central database (replace `admin' with the name of the user account
under which cylc was installed). If there are a lot of suites in the
central database, use View $\rightarrow$ Filter to restrict the view
(you can leave the dialog open and refilter as often as you like).

Now right click on the {\em examples} group and choose `Import' to 
copy the whole group of suites to your private database. A dialog box
will pop up allowing you to register your copy under a different group
(leave this as it is) and a destination for the suite definition
directories in the group (choose something like
\lstinline=$HOME/suites/examples=). 

{\em Note that you can also import individual suites, and that
registration groups do not need to be created explicitly, they
are automatically created and deleted as required.} 

Now use the Database menu to switch back to your private database, and
confirm that you now have a copy of the example suites.

\subsubsection{By The Command Line}

Here's how to do the same thing on the command line:

%\lstset{ basicstyle=\color{basic}\scriptsize\ttfamily }
\begin{lstlisting}
$ cylc db import admin:examples: $HOME/suites/examples
Matched:
   admin:examples:CUG1
   admin:examples:CUG73
   admin:examples:CUG74
   admin:examples:CUG_QS1
   admin:examples:CUG_QS2
   admin:examples:CUG_QS3
   admin:examples:FFHook
   admin:examples:FFTask
Locking database /home/oliverh/.cylc/LDB/db
REGISTERED examples:CUG1 "<SNIP> Example 1" ~oliverh/suites/examples/CUG1
Copying suite definition
REGISTERED examples:CUG73 "<SNIP> Graph Example" ~oliverh/suites/examples/CUG73
Copying suite definition
REGISTERED examples:CUG74 "A two-task test suite" ~oliverh/suites/examples/CUG74
Copying suite definition
REGISTERED examples:CUG_QS1 "<SNIP> Example 1" ~oliverh/suites/examples/CUG_QS1
Copying suite definition
REGISTERED examples:CUG_QS2 "<SNIP> Example 2" ~oliverh/suites/examples/CUG_QS2
Copying suite definition
REGISTERED examples:CUG_QS3 "<SNIP> Example 3" ~oliverh/suites/examples/CUG_QS3
Copying suite definition
REGISTERED examples:FFHook  "<SNIP> script example"  ~oliverh/suites/examples/FFHook
Copying suite definition
REGISTERED examples:FFTask  "<SNIP> task example"  ~oliverh/suites/examples/FFTask
Copying suite definition
Unlocking database /home/oliverh/.cylc/LDB/db
DONE
\end{lstlisting}
(suite title strings have been truncated again to reduce line length).
%\lstset{ basicstyle=\color{basic}\footnotesize\ttfamily }

\subsubsection{Private Suite Database Actions}

By right-clicking on a suite in your private database, or using the cylc
command line, you can:
\begin{myenumerate}
    \item start a suite control GUI to run the suite (or connect to a running suite),
    \item submit a single task to run, just as it would be submitted by its suite
    \item view the cylc stdout and stderr streams for the suite,
    \item view the cylc log for the suite (which records all events and messages),
    \item retrieve the suite description,
    \item list tasks in the suite,
    \item edit the suite definition in your editor,
    \item plot the suite dependency graph,
    \item search the suite definition and bin scripts,
    \item validate the suite definition,
    \item copy the suite or group,
    \item compare (difference) the suite with another suite,
    \item export the suite or group to the central database,
    \item unreregister the suite or group,
    \item reregister the suite or group.
\end{myenumerate}


\subsection{Viewing The examples:CUG\_QS1 Suite Definition}

Right-click on the suite and choose `Edit', or use the edit command,
\begin{lstlisting}
$ cylc edit examples:CUG_QS1
\end{lstlisting}
to view the suite definition (suite.rc file) in your editor. 

This moves to the suite definition directory (so that you can easily
open other suite files in the same edit session) and opens the
suite.rc file in your chosen editor. You can of course
do this manually, but the automated way is quick and convenient,
you don't have to remember suite definition directory locations, and
for suite.rc files that contain include files you can
optionally {\em edit the file inlined - it will be split back into its
constituent include-files when you save the file and exit the editor}. 

If you use the vim editor you can have nice cylc-specific syntax
highlighting and section folding; see Section~\ref{SyntaxHighlighting}
for a screenshot and instructions. 

You should see the following suite.rc file in your editor: 

\lstinputlisting{../examples/CUG5/one/suite.rc}

This defines a complete, valid, runnable suite. To understand suite.rc
files in detail, read {\em Suite Definition}
(Section~\ref{SuiteDefinition}). Here's how to interpret this
one: 

At 0, 6, 12, and 18 hours each day a clock-triggered task called GetData
triggers 1 hour after the wall clock reaches its (GetData's) nominal cycle
time; then a task called Model triggers when GetData finishes;
and a task called PostA triggers when Model is finished. Additionally,
Model depends on its own previous instance from 6 hours earlier; and twice
per day at 6 and 18 hours another task called PostB also triggers off Model.

All the tasks in this suite can run in parallel with their own previous
instances if the opportunity arises (i.e.\ if their prerequisites
happen to be satisfied before the previous instance is finished).
Most tasks should be capable of this (see Section~\ref{LimitPID}) but if
necessary you can force particular tasks to run sequentially without
using an explicit trigger on their own previous instance, e.g.: 
\begin{lstlisting}
# SUITE.RC
[special tasks]
    sequential = GetData
\end{lstlisting}

Finally, when the suite is first {\em cold started} from scratch it is
made to wait on a special {\em startup} task
called Prep. Startup tasks are one off tasks (non-spawning) that are 
only used at suite startup, and any dependence on a startup task in the
suite graph only applies at suite startup.

The optional visualization section, fairly obviously, just defines
properties used to plot the suite graph, which we'll do next.

\subsection{Plotting The examples:CUG\_QS1 Dependency Graph}

Right-click on the {\em examples:CUG\_QS1} suite in gcylc and choose Graph; or on
the command line,
\begin{lstlisting}
$ cylc graph examples:CUG_QS1 2011052300 2011052318 &
\end{lstlisting}
This should pop up a zoomable, pannable, graph viewer showing
the graph of Figure~\ref{fig-QuickStartA-graph18}. 

{\em If you edit the suite.rc file while viewing the graph, the viewer
will update whenever you save the file}.\footnote{Unless you're editing
a temporarily inlined suite.rc file, in which case it will update when
you save the file and exit the editor.}

\begin{figure}
    \begin{center}
        \includegraphics[width=0.7\textwidth]{screenshots/QuickStartA-graph18.png}
    \end{center}
    \caption[The {\em examples:CUG\_QS1} dependency graph]{\small The
    {\em examples:CUG\_QS1} dependency graph.}
\label{fig-QuickStartA-graph18}
\end{figure}

\subsection{Running The examples:CUG\_QS1 Suite}

Each cylc task has command scripting that is called to invoke task
processing when the task is ready to run. No task commands have
been defined in our example suite so the tasks all default to the 
{\em dummy task} command line:
\lstset{language=bash}
\begin{lstlisting}
# SUITE.RC
[tasks]
    [[GetData]]
        command = "echo DUMMY $TASK_ID; sleep $CYLC_SIMULATION_SLEEP"
\end{lstlisting}
where \lstinline=$TASK_ID= is \lstinline=NAME%YYYYMMDDHH=) and 
\lstinline=$CYLC_SIMULATION_SLEEP= defaults to 10 seconds. This just
writes an identifying message to stdout and then sleeps for a few
seconds before exiting. 

Now start a suite control GUI by right-clicking on the suite in gcylc
and choosing `Control (graph)'.  You can also open a treeview control
GUI for the same suite, if you like. Multiple GUIs running at the same
time will automatically connect to the same running suite (they won't
try to run separate instances). Note also that if you shut down a 
suite control GUI, the suite will keep running. You can reconnect 
to it later by opening another control GUI.
{\em See {\em The Graph-Based Suite Control GUI}, 
Section~\ref{TheGraphBasedSuiteControlGUI}.}

In the control GUI click on Control $\rightarrow$ Run, enter an initial
cold start cycle time (e.g.\ 2011052306), and select ``Hold (pause) on
startup'' so that the suite will start in the held state (tasks
will not be submitted even if they are ready to run). 

{\em Do not choose an initial cycle time in the future, unless you're
running in simulation mode, or nothing will happen until that time.}

If the initial cycle time ends in 06 or 18 
the suite controller should look like
Figure~\ref{fig-QuickStartA-ControlStart06},
or otherwise (00 or 12) like
Figure~\ref{fig-QuickStartA-ControlStart00}.

\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{screenshots/QuickStartA-ControlStart06.png}
    \end{center}
    \caption[Suite {\em examples:CUG\_QS1} at startup, 06 or 18 hours.]{\small
    Suite {\em examples:CUG\_QS1} at startup with an initial
    cycle time ending in 06 or 18 hours. Blue nodes indicate tasks
    in the waiting state.}
    \label{fig-QuickStartA-ControlStart06}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{screenshots/QuickStartA-ControlStart00.png}
    \end{center}
    \caption[Suite {\em examples:CUG\_QS1} at startup, 00 or 12
    hours]{\small Suite {\em examples:CUG\_QS1} at startup with an
    initial cycle time ending in 00 or 12 hours. Blue nodes represent 
    tasks in the waiting state and off-white nodes are tasks from the 
    base graph, defined in the suite.rc file, that aren't currently live
    in the suite.}
    \label{fig-QuickStartA-ControlStart00}
\end{figure} 

The reason for the difference in graph structure between the two figures
is this: cylc starts up with every task present, in the waiting
state (blue), at the initial cycle time {\em or} at the first
subsequent valid cycle time for the task - and PostB does not run at 00
or 12. The off-white tasks are from the base graph, defined in the 
suite.rc file, and aren't actually present in the suite as yet (they
are shown in the graph in order to put the live tasks in context).

Now, click on Control $\rightarrow$ Release in the suite control GUI
to {\em release the hold on the suite}, 
and observe what happens: the GetData tasks will rapidly go off 
in parallel out to a few cycles ahead , and then the suite will stall,
as shown in Figures~\ref{fig-QuickStartA-ControlRunning}
and~\ref{fig-QuickStartA-ControlStalled}. 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{screenshots/QuickStartA-ControlRunning.png}
    \end{center}
    \caption[Suite {\em examples:CUG\_QS1} running.]
    {\small Suite {\em examples:CUG\_QS1} running, showing multiple
    instances of the clock-triggered GetData task running at once.}
    \label{fig-QuickStartA-ControlRunning}
\end{figure} 
\begin{figure}
    \begin{center}
        \includegraphics[width=0.8\textwidth]{screenshots/QuickStartA-ControlStalled.png}
    \end{center}
    \caption[ Suite {\em examples:CUG\_QS1} stalled.]
    {\small Suite {\em examples:CUG\_QS1} stalled after the
    clock-triggered GetData tasks have finished, because of Model's
    previous-cycle dependence and the suite runahead limit (see main
    text).}
    \label{fig-QuickStartA-ControlStalled}
\end{figure} 

The Prep task runs immediately because it has no prerequisites and is
not clock-triggered. The clock-triggered GetData tasks then all go off
at once because they have no prerequisites (i.e.\ they do not have to
wait on any upstream tasks), their trigger time has long passed (the
initial cycle time was in the past), and they are not sequential tasks
(so they are able to run in parallel - try declaring GetData
sequential to see the difference).
They don't spawn beyond four cycles ahead though, thanks to the suite 
``runahead limit'' which is set to 12 hours in the suite.rc file. The
runahead limit is designed to stop free tasks like this from running off
too far into the future. It is of no conseqence in normal real time
operation\footnote{So long as it is sufficient to span the normal
range of cycle times present in the suite - task that only run once 
per day, for example, have to spawn a successor that is 24 hours 
ahead.} because the clock triggered tasks are then constrained by the
wall clock, and the other tasks have to wait on them.

\subsubsection{Viewing Task States}

If you're wondering why a particular task has not triggered yet in a
running suite you can view the current state of its prerequisites 
by right-clicking on the task and choosing `View State', or using
\lstinline=cylc show=. Do this for the first Model task, which appears 
to be stuck in the waiting state, to get a small window like  
Figure~\ref{fig-QuickStartA-ModelState}.

\begin{figure}
    \begin{center}
        \includegraphics[width=0.4\textwidth]{screenshots/QuickStartA-ModelState.png}
    \end{center}
    \caption[Viewing current task state in gcylc]
{\small Viewing current task state after right-clicking on a task in gcylc. The
    same information is available from the \lstinline=cylc show= command.}
    \label{fig-QuickStartA-ModelState}
\end{figure} 

It is clear that the reason the task is not running, and consequently, by
virtue of the runahead limit, why the suite as a whole has stalled, is
that Model(T) is waiting on Model(T-6) which does not exist at suite
startup. Model represents a warm-cycled forecast model that depends on a
``model background'' or ``restart file(s)'' generated by its own
previous run.

\subsubsection{Triggering Tasks Manually}

Right-click on the waiting Model task and choose Trigger, or use
\lstinline=cylc trigger=, to force the task to trigger, and thereby get
the suite up and running. In a real suite this would not be sufficient:
the real forecast model that Model represents would fail for lack of the
real restart files that it requires as input.  Well see how to handle
this properly shortly.

\subsubsection{Shutting Down And Restarting A Suite}

Having watched the {\em examples:CUG\_QS1} suite run for a while, choose
Stop from the Control menu, or \lstinline=cylc stop=, to shut it down.
The default stop method waits for any tasks that are currently running
to finish before shutting the suite down, so that the final recorded
suite state is perfectly consistent with what actually happened.  

You can restart the suite from where it left off by choosing 
Control $\rightarrow$ Run and selecting the `restart' option, or using
\lstinline=cylc restart=. {\em Note that cylc always writes a special
state dump, and logs its name, prior to actioning any intervention, and
you can also restart a suite from one of these states, rather than the 
default most recent state, in case you make a mistake.}

\subsection{examples:CUG\_QS2 - Handling Model Cold Starts Properly}

Now take a look at {\em examples:CUG\_QS2}, which is a minor
modification of {\em examples:CUG\_QS1}. Its suite.rc file has a new
{\em cold start} task called ColdModel,

\begin{lstlisting}
# SUITE.RC
[special tasks]
    cold start = ColdModel
\end{lstlisting}
and the dependency graph (see also Figure~\ref{fig-QuickStartB-graph18})
looks like this:
\begin{lstlisting}
# SUITE.RC
[dependencies]
    [[ 0,6,12,18 ]]
        graph  =  """Prep => GetData & ColdModel
                     GetData => Model => PostA
                     ColdModel | Model(T-6) => Model"""
    [[ 6,18 ]]
        graph = "Model => PostB"
\end{lstlisting}

In other words, Model can trigger off {\em either} its previous-cycle
self {\em or} ColdModel in the same cycle. 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.7\textwidth]{screenshots/QuickStartB-graph18.png}
    \end{center}
    \caption[The {\em examples:CUG\_QS2} graph with model cold start task.]{\small
    The {\em examples:CUG\_QS2} dependency graph showing a model cold
    start task.}
\label{fig-QuickStartB-graph18}
\end{figure}

A cold start task is a one off task used to satisfy the previous-cycle
dependence of a cotemporal task whose previous-cycle trigger is not
available. The obvious use for this is to cold start warm-cycled
forecast models at suite startup, when there is no previous cycle.
Unlike startup tasks though, cold start dependencies are not restricted
to suite startup because it is sometimes useful to be able to 
insert a cold start task into a running suite, to get a model restarted
after it had to skip one or more cycles due to problems, without having
to restart the whole suite.

{\em A model cold start task in a real suite often submits a real ``cold
start forecast'' to generate the previous-cycle input files required by
its associated model}.  Or it could just stand in for some external
spinup process, or similar, that has to be completed before the suite
starts - in this case the cold start task would be a dummy task 
that just reports successful completion in order to satisfy the initial
previous-cycle dependence of the model.

If you run {\em examples:CUG\_QS2} you'll see that no manually
triggering is required to get the suite started this time.


\subsection{examples:CUG\_QS3 - With Task Implementation}

The suite {\em examples:CUG\_QS3} is the same as {\em examples:CUG\_QS2}
except that it has real task implementations - scripts located
in the suite bin directory that generate output files and consume input
files in such a way that they have to run according to the graph of
Figure~\ref{fig-QuickStartB-graph18}. The suite gets them to run
together out of a common I/O workspace, configured via the suite.rc
file. 

By studying this suite and its tasks, and by making quick copies of 
it to modify and run, you should be able to learn a lot about how 
to build real cylc suites.

\subsection{Following What's Happening In A Running Suite}

\subsubsection{Suite Stdout and Stderr}

When cylc runs a suite it writes warnings and other informative messages,
such as when and how each task is submitted, to the stdout stream. If 
you start a suite at the command line, what happens to this output is
entirely up to you. If you start a suite via gcylc, however, the output is 
directed to a special file, \lstinline=$HOME/.cylc/SUITE.out= that can
be accessed again later if you reconnect to the suite with a new control
GUI.

\begin{figure}
    \begin{center}
        \includegraphics[width=0.7\textwidth]{screenshots/suite-output.png}
    \end{center}
\caption[Cylc suite stdout/stderr example.]{\small Cylc suite stdout/stderr example.}
\label{fig-suite-output}
\end{figure}

\subsubsection{Suite Logs}

The cylc suite log records every event that occurs (incoming messages from tasks
and so on) along with the time of the event. The top level logging directory,
under which a suite-specific log is written, is configurable in the suite.rc file.
Suite logs are (optionally) rolled over at start up and the 5 most
recent back ups are automatically kept.

\begin{figure}
    \begin{center}
        \includegraphics[width=0.7\textwidth]{screenshots/suite-log.png}
    \end{center}
\caption[ A cylc suite log viewed via gcylc.]{\small A cylc suite log viewed via gcylc.}
\label{fig-suite-log}
\end{figure}

Figure~\ref{fig-suite-log} shows a suite log viewed from within gcylc. The 
\lstinline=cylc log= command also enables viewing and filtering of suite logs
without having to remember the actual log file location.

\subsubsection{Task Stdout and Stderr Logs}

The stdout and stderr logs generated when a task is submitted end up
in the suite.rc {\em job submission log directory}, 
default location \lstinline=$HOME/CylcJobLogs/GROUP/NAME/=.
These files will contain the complete stdout and stderr record
for tasks whose initiating processes do not detach and exit 
before all task processing is finished. 
The final location of the internal output of detaching tasks, whose
initiating processes submit internal jobs before exiting early, is up to
the task implementation.

\subsection{Searching A Suite}

The cylc suite search tool reports matches in the suite.rc file
by line number, suite section, and file, even if nested include-files
are used, and by file and line number for matches in the suite bin
directory.  The following output listing is from a search of
the {\em examples:CUG3} suite, which has some task scripts in the suite
bin directory. 
\begin{lstlisting}
$ cylc grep OUTPUT_DIR examples:CUG3

SUITE: examples:CUG_QS3
PATTERN: OUTPUT_DIR

FILE: /home/admin/cylc/examples/CUG5/three/suite.rc
   SECTION: [tasks]->[[GetData]]->[[[environment]]]
      [47]:             GETDATA_OUTPUT_DIR = $WORKSPACE
   SECTION: [tasks]->[[ColdModel]]->[[[environment]]]
      [54]:             MODEL_OUTPUT_DIR = $WORKSPACE
   SECTION: [tasks]->[[Model]]->[[[environment]]]
      [62]:             MODEL_OUTPUT_DIR = $WORKSPACE
   SECTION: [tasks]->[[PostA]]->[[[environment]]]
      [70]:             POSTA_OUTPUT_DIR = $WORKSPACE
   SECTION: [tasks]->[[PostB]]->[[[environment]]]
      [77]:             POSTB_OUTPUT_DIR = $WORKSPACE

FILE: /home/admin/cylc/examples/CUG5/three/bin/PostA.sh
   [7]: cylc checkvars -c POSTA_OUTPUT_DIR
   [21]: touch $POSTA_OUTPUT_DIR/surface-wind.products

FILE: /home/admin/cylc/examples/CUG5/three/bin/GetData.sh
   [6]: cylc checkvars -c GETDATA_OUTPUT_DIR
   [11]: touch $GETDATA_OUTPUT_DIR/obs-${CYCLE_TIME}.nc

FILE: /home/admin/cylc/examples/CUG5/three/bin/PostB.sh
   [7]: cylc checkvars -c POSTB_OUTPUT_DIR
   [21]: touch $POSTB_OUTPUT_DIR/precip.products

FILE: /home/admin/cylc/examples/CUG5/three/bin/Model.sh
   [11]: cylc checkvars -c MODEL_OUTPUT_DIR MODEL_RUNNING_DIR
   [54]: touch $MODEL_OUTPUT_DIR/surface-winds-${CYCLE_TIME}.nc
   [55]: touch $MODEL_OUTPUT_DIR/precipitation-${CYCLE_TIME}.nc
DONE
\end{lstlisting}
(The same thing can of course be done via the gcylc right-click menu).

\subsection{Comparing Suites}

Cylc can also compare suites and report differences by suite.rc 
section and item. For instance, comparing the example suites 
\lstinline=CUG_QS1= and \lstinline=CUG_QS2= by GUI or command line
results in:

\begin{lstlisting}
$ cylc diff examples:CUG_QS1 examples:CUG_QS2

Suite definitions examples:CUG_QS1 and examples:CUG_QS2 differ.

1 items only in examples:CUG_QS1 (<)

   [visualization] [[node attributes]]
 <   Model = ['style=filled', 'fillcolor=red']

3 items only in examples:CUG_QS2 (>)

   [visualization] [[node attributes]]
 >   models = ['style=filled', 'fillcolor=red']
 >   ColdModel = ['fillcolor=lightblue']

   [visualization] [[node groups]]
 >   models = ['ColdModel', 'Model']

7 common items differ examples:CUG_QS1(<) examples:CUG_QS2(>)
# (some have been omitted here for inclusion in the User Guide!)

   (top)
 <   suite log directory = /home/oliverh/CylcSuiteLogs/examples/CUG_QS1
 >   suite log directory = /home/oliverh/CylcSuiteLogs/examples/CUG_QS2

   [special tasks]
 <   cold start = []
 >   cold start = ['ColdModel']

   [dependencies] [[0,6,12,18]]
 <   graph = Prep => GetData => Model => PostA
                     Model(T-6) => Model
 >   graph = Prep => GetData & ColdModel
                     GetData => Model => PostA
                     ColdModel | Model(T-6) => Model
DONE
\end{lstlisting}
(some output has been omitted for brevity). Note that the {\em suite log
directory} items differ even though they are not explicitly defined in 
either suite.  That is because their default values (see the {\em
Suite.rc Reference}, Appendix~\ref{SuiteRCReference}) are suite-specific.

\subsection{Validating A Suite}

After editing a suite always validate it to check for errors, via 
gcylc or the \lstinline=cylc validate SUITE= command.
Figure~\ref{fig-validate-eg} shows validation of 
{\em examples:CUG73} (unfortunately the suite was registered under 
a different name when the screenshot was taken). Note the warnings
that the tasks will be dummied out, as discussed above. 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.5\textwidth]{screenshots/validate-eg.png}
    \end{center}
    \caption[Suite {\em examples:CUG73} Validation.]{\small Suite
    {examples:CUG73} Validation.}
\label{fig-validate-eg}
\end{figure}

For more information on suite validation see
Section~\ref{Validation}.

\subsection{Using Example Suites To Understand Cylc}

Cylc has been designed from the ground up to make testing and
prototyping very easy. Simply drawing (in text) a dependency graph in a
new suite.rc file creates a valid suite that you can run. The tasks will
default to emitting an identifying message, sleeping for a few seconds,
and then exiting; but you can then arrange for particular tasks to do
more complex things (to fail, for example) by supplying appropriate task
command lines to replace the default ``dummy'' one.

Cylc's example suites run quickly and are portable: you can copy and run
them immediately without modification, even those with real task
implementations that generate real (albeit zero-sized) output files. You
can even run multiple copies of the same example suite at once (even
multiple {\em instances} of the exact same suite, in fact), under
different registrations, because the suite group and name are used in
all I/O paths (without being hardwired anywhere).

You can copy an example suite in an instant, using the cylc commands or
GUI, make a few changes according to your needs, and then run it to see
what happens.

You can also run real suites in simulation mode, wherein each real task is
replaced by the default dummy task (above) and the suite runs quickly on
an accelerated clock. As far as cylc is concerned this is almost
identical to real operation, so simulation mode can be used to test recovery
strategies for certain kinds of failure, for instance. In simulation mode you
can watch how any suite catches up and transitions from delayed to real
time operation.

The lockserver will let you run multiple instances of any suite, 
under different registrations, if the suite declares 
{\em allow multiple simultaneous instances = True} in its suite.rc file. 
This should only be used if \lstinline=$CYLC_SUITE_GROUP= and 
\lstinline=$CYLC_SUITE_NAME= are used in all I/O paths so that the
different suite instances will not interfere with each other.

%\pagebreak
\section{Suite Registration}
\label{SuiteRegistration}

How to construct a cylc suite is described in following sections of the
User Guide. The cylc command set includes tools to aid in suite
construction as well as suite control, however, and before you can do
anything to a suite with cylc commands you must register it in
your {\em private suite database}. 

\subsection{Private Suite Databases}

Your private suite registration database simply maps suites,
organised by GROUP and NAME, to their suite definition locations (see
{\em Suite Definition}, Section~\ref{SuiteDefinition}). You can then
refer to your suites concisely ``by name'' without having to specify,
or even remember, where the suite definition resides.
For example this command lists all the tasks in suite `foo' of the `oper' group.
\begin{lstlisting}
$ cylc info list oper:foo
\end{lstlisting}

By right-clicking on a suite in the private database, or using cylc commands, you can:
\begin{myenumerate}
    \item start a suite control GUI to run the suite (or connect to a running suite),
    \item submit a single task to run, just as it would be submitted by its suite,
    \item view the cylc stdout and stderr streams for the suite,
    \item view the cylc log for the suite (which records all events and messages),
    \item retrieve the suite description,
    \item list tasks in the suite,
    \item edit the suite definition in your editor,
    \item plot the suite dependency graph,
    \item search the suite definition and bin scripts,
    \item validate the suite definition,
    \item copy the suite or group,
    \item compare (difference) the suite with another suite,
    \item export the suite or group to the central database,
    \item unreregister the suite or group,
    \item reregister the suite or group.
\end{myenumerate}

Note that the suite title shown in gcylc is parsed
from the suite.rc file at the time of initial registration; if you
change the title (by editing the suite.rc file) use 
\lstinline=cylc db refresh= or gcylc 
View $\rightarrow$ Refresh to update the database.


\subsection{The Central Suite Database}

The central suite database facilitates sharing of suites among cylc
users without cluttering the public namespace with suites that are
partially completed, broken, or not generally useful. It works similarly
to a private suite database except that suites are organised by {\em
owner} as well as group and name.  Users can export suites to the
central database to make them available to others. During export you can
choose to have the suite definition copied to the database (the suite
definition itself isn't ``stored in the database'' but the new
registration will refer to the new centrally located suite definition)
or you can have to central database reference the original suite.

Suites in the central database can be inspected by various means, but
you can't run them without {\em importing} them to your private database.

By right-clicking on a suite in the central database, or using the cylc
command line, you can:
\begin{myenumerate}
    \item retrieve the suite description,
    \item list tasks in the suite,
    \item view the suite definition in your editor,
    \item plot the suite dependency graph,
    \item search the suite definition and bin scripts,
    \item validate the suite definition,
    \item compare (difference) the suite with another suite,
    \item import the suite or group to your private database,
    \item unreregister or delete the suite or group (if you own it),
    \item reregister the suite or group (if you own it).
\end{myenumerate}

\subsubsection{Can Suites Be Shared Across The Network?}

The central suite database is not currently accessible on the
network, it is local to the cylc host and accessed through the 
filesystem. Consequently it has to be world, or at least group,
writeable, which is not very secure.

%Also it briefly locks users out during operations that change the
%        minimal
%registration data (i.e.\ the mappings between suite names and locations,
%not when copying suite definitions to the central location, which is
%potentially time consuming). 

{\em We intend to develop a client/server interface to the public suite
database so that users can easily share suites across the network}. The 
required server functionality is essentially identical to that of the
cylc lockserver, so this will not be difficult. In the meantime,
``importing'' a suite manually from another user on another host is
simply a matter of copying the suite definition directory over and
registering the new copy in your private database.

\subsection{Database Operations}

On the command line, the  `database' (or `db') command category contains
commands to implement the aforementioned operations.

\lstset{language=usage}
\lstinputlisting{command-usage/database.txt}

The same functionality is also available by right-clicking on suites
or groups in the gcylc GUI, as shown in Figure~\ref{fig-db}.

%\pagebreak
\section{Suite Definition} 
\label{SuiteDefinition}

A cylc suite is defined entirely by a single structured, validated, {\em
suite.rc file} that concisely specifies the properties of, and the
relationships between, the various tasks managed by the suite. 

This section of the User Guide deals with the format and content of the
suite.rc file, including task definition.  Task {\em implementation} - 
what's required of the real commands, scripts, or programs that
do the processing that the tasks represent, is covered in
Section~\ref{TaskImplementation}.

%for how to write the suite.rc dependency graphs that determine the
%structure of your suite see {\em Suite.rc Dependency Graphs}
%(Section~\ref{DependencyGraphs}) ; for how to construct the tasks 
%that do the real processing in a cylc suite see {\em Task
%Implementation} (Section~\ref{TaskImplementation}), and for how cylc
%tasks are actually submitted to run, see{\em Job Submission} 
%(Section~\ref{JobSubmission}).

\subsection{The Suite Definition Directory}

A cylc {\em suite definition directory} contains:
\begin{myitemize}
    \item {\bf a suite.rc file}: this is {\em the} suite definition
    \item any include-files used by the suite.rc file (see Appendix~\ref{IncludeFiles})
        %\begin{myitemize}
        %    \item use of include-files is optional
        %    \item these may be kept in sub-directories, 
        %    \item paths should be specified portably, relative to the
        %        suite definition directory
        %\end{myitemize}
    \item {\bf a bin directory} for scripts and programs that implement,
        or are used by, suite tasks
        \begin{myitemize}
            \item technically optional - tasks can call external
                commands, scripts, or programs 
            \item tasks get automatic access to their own suite bin directory
        \end{myitemize}
    \item any other suite-related documentation, control files, etc.
        \begin{myitemize}
            \item whole suite definition directories are copied if you
                copy a suite
            \item files in the suite definition directory can be
                accessed portably by tasks at run time 
                through the environment variable \lstinline=$CYLC_SUITE_DIR=
                supplied by the suite (see
                {\em Task Execution Environment}
                (Section~\ref{TaskExecutionEnvironment})
            \item holding everything in one place makes revision control
                easy
        \end{myitemize}
\end{myitemize}

Here's an imaginary example,

\begin{lstlisting}
/path/to/my/suite   # suite definition directory
    suite.rc           # <-- SUITE DEFINITION FILE
    bin/               # bin directory (scripts, programs)
        foo.sh
        bar.sh
        ...
    # (OPTIONAL) any other suite-related files, for example:
    inc/               # suite.rc include-files
        nwp-tasks.rc
        globals.rc
        ...
    doc/               # documentation
    control/           # control files
    ancil/             # ancillary files
    ...
\end{lstlisting}

\subsection{The suite.rc File}
\label{SuiteRCFile}

Cylc suite.rc files parse directly into a nested data structure inside
cylc, which makes it very easy to add and use new configuration items.

Suite.rc files are validated against a specification file 
(\lstinline=$CYLC_DIR/conf/suiterc.spec=) that defines all legal
entries, values, options, and defaults; these are documented
in detail in the {\em Suite.rc Reference}
(Appendix~\ref{SuiteRCReference}).

\subsubsection{Syntax}

\begin{myitemize}
    \item {\bf Entries} take the form \lstinline@item = value@.
    \item {\bf Comments} follow a hash character (\#) to the end of the line.
    \item {\bf Single Line Strings} are quoted, but quotes can be 
        omitted if the string contains no commas 
        (which indicate a list value).
    \item {\bf Multiline Strings} are triple-quoted.
    \item {\bf List Values} are comma separated.
    \item {\bf White Space} is ignored but you can indent for clarity.
    \item {\bf Continuation Lines} follow a trailing backslash.
    \item {\bf Sections}
        \begin{myitemize}
            \item nesting is determined by the number of square
        brackets around the section heading.
            \item sections are closed by the next section heading,
                so within a section all top level items must be defined
                before any subsections (and similarly for lower levels
                of nesting).
        \end{myitemize}
    \item {\bf Include-files} can be multiply-included and nested. 
        Paths are specified, portably, relative to the suite definition
        directory. Inclusions can span section boundaries.
    \item  Duplicate items are allowed in environment and directives
        sections (this is good for overriding defaults held in an
        include-file).
\end{myitemize}

The following pseudo-listing illustrates the file structure:

\begin{lstlisting}
# comment
item = value # trailing comment
a string item = the quick brown fox
another string item = "the quick brown fox"
yet another string item = """the quick brown fox
jumped over the lazy dog"""
a list item = foo, bar, baz
a list item with continuation = a, b, c, \
                                d, e, f
[section]
    item = value
%include inc/vars/foo.inc  # include file
    [[subsection]]
        item = value
        [[[subsubsection]]]
            item = value
[another section]
    [[another subsection]]
        # ...
    # ...
# ...
\end{lstlisting}

\subsubsection{An Example}

A typical suite.rc file might contain the following information:
\begin{myitemize}
    \item suite title
    \item suite description
    \item a default job submission method for the suite
    \item lists of tasks with special behaviour (e.g. clock-triggered tasks)
    \item a dependency graph defining the relationships between tasks
    \item a global environment section (variables available to all tasks)
    \item and for each task,
        \begin{myitemize}
            \item task description
            \item task-specific environment section (variables available to just this task)
            \item the command scripting to execute when the task is
                ready to run
        \end{myitemize}
    \item optionally, a visualization section to configure graph plotting for the suite
\end{myitemize}

Here's an example: 

\begin{lstlisting}
# GLOBAL SETTINGS
title = suite foo

description = """Run Model on real time input data and postprocess its 
output with PostA, four times daily; twice daily do additional
postprocessing with PostB."""

job submission method = loadleveler
 
[special tasks]
    # TASKS WITH UNUSUAL BEHAVIOUR
    cold start       = ColdModel
    clock-triggered = GetData(1)

[dependencies]
    # THE SUITE DEPENDENCY GRAPH
    [[ 0,6,12,18 ]]  # four times daily
        graph  =  """
            GetData => Model => PostA
            ColdModel | Model(T-6) => ModelA  # model cold start or restart
                  """
    [[ 6,18 ]]  # additional postprocessing at 6 and 18 UTC
        graph = "Model => PostB" 

[environment]
    # ENVIRONMENT VARIABLES AVAILABLE TO ALL TASKS
    WORKSPACE = /$TMPDIR/$CYLC_SUITE_GROUP/$CYLC_SUITE_NAME

[tasks]
    # COMMAND AND EXECUTION ENVIRONMENT FOR EACH TASK
    [[GetData]]
        description = "retrieve data for the current cycle time"
        command = GetData.sh
        [[[environment]]]
            # ENVIRONMENT VARIABLES AVAILABLE TO THIS TASK
            GETDATA_OUTPUT_DIR = $WORKSPACE
    [[Model]]
        # ...
    [[PostA]]
        # ...

[visualization]
    # NODE AND EDGE PROPERTIES FOR DEPENDENCY GRAPH PLOTTING
    # ...
\end{lstlisting}

This is in fact the {\em examples:CUG\_QS3} suite from the Quick Start Guide,
which you can copy, study, and run. Dependency graphs plotted from this
(by gcylc or \lstinline=cylc graph=) are shown in
Figures~\ref{fig-simple-graph-1} and~\ref{fig-simple-graph-3}.

Subsequent sections of the User Guide explain important parts of the
suite.rc file in detail. To see what else can go in a suite definition,
study other example suites and refer to the {\em Suite.rc Reference}
(Appendix~\ref{SuiteRCReference}).

\begin{figure}
\begin{minipage}[t]{0.35\textwidth}
    \begin{center}
        \includegraphics[width=\textwidth]{screenshots/simple-6-cold.png}
    \end{center}
\end{minipage}
\hfill
\begin{minipage}[t]{0.35\textwidth}
    \begin{center}
        \includegraphics[width=\textwidth]{screenshots/simple-6-warm.png}
    \end{center}
\end{minipage}
\caption[Dependency graphs for a simple example suite]{\small
Dependency graphs (cold and warm start) plotted from a simple suite.rc file.}
\label{fig-simple-graph-1}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[height=0.4\textheight]{screenshots/simple-18-cold.png}
    \end{center}
\caption[Three cycle cold start dependency graph for the simple example
suite]{\small Three cycle cold start dependency graph plotted by `cylc
graph' from the simple example suite.rc file, showing variation
between cycles.}
\label{fig-simple-graph-3}
\end{figure} 

\clearpage

\subsubsection{Syntax Highlighting In Vim}
\label{SyntaxHighlighting}

Cylc comes with a syntax file to configure suite.rc syntax
highlighting and section folding in the {\em vim} editor, as shown in
Figure~\ref{fig-cylc-vim}. To use this, copy 
\lstinline=$CYLC_DIR/conf/cylc.vim= to your
\lstinline=$HOME/.vim/syntax/= directory and make some minor
modifications, as described in the syntax file, to your
\lstinline=$HOME/.vimrc= file.

%\begin{figure}
%    \begin{center}
%        \includegraphics[width=14cm]{screenshots/simple-suiterc.png}]
%    \end{center}
%    \caption[Cylc suite.rc syntax highlighting in vim]{
%    Cylc suite.rc syntax highlighting and folding in the vim editior.}
%    \label{fig-cylc-vim} 
%\end{figure} 


\subsection{Dependency Graphs}
\label{DependencyGraphs}
 
Dependency graphs define the relationships between tasks in a suite. 
The cylc suite.rc graph notation makes clear textual representations of
actual graphs, but it is more concise
than the real thing because sections of the graph that repeat at
different hours of the day only have to be defined once.

Figure~\ref{fig-dep-eg-1} shows an example alongside its graphical
representation, plotted with,
\lstset{language=bash}
\begin{lstlisting}
$ cylc graph examples:CUG73 2011052200 2011052206
# (or use right-click Graph in gcylc)
\end{lstlisting}

Incidentally, the suite.rc file listed in Figure~\ref{fig-dep-eg-1} is 
a complete valid suite definition that you can run (just import a copy
from the central suite database and run it): cylc will run dummy tasks,
which sleep for a few seconds then emit an identifying message,
because task command scripting has not been specified. If you do try to
run Example 1, be aware that you'll need to trigger task A manually to
get the suite started. That's because A(T) depends on its own previous
instance A(T-6), and at startup there is no previous cycle to satisfy
that prerequisite.  How to handle a {\em cold start} properly is
described below in {\em Satisfying Intercycle Dependencies At Startup}
(Section~\ref{SatisfyingIntercycleDependenciesAtStartup}) and in the
{\em Quick Start Guide} (Section~\ref{QuickStartGuide}).

\begin{figure}
\begin{minipage}[b]{0.5\textwidth}
%    \lstset{basicstyle=\color{basic}\scriptsize\ttfamily}
\begin{lstlisting}
# SUITE.RC
title = "Dependency Graph Example (Ch.6)"
[dependencies]
    [[0,6,12,18]] # hours
        graph = """
A => B & C   # B and C trigger off A
A(T-6) => A  # Model A restart trigger
                """
    [[6,18]] # hours
        graph = "C => X"
[visualization]
    [[node attributes]]
        X = "color=red"
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}[b]{0.5\textwidth}
    \begin{center}
        \includegraphics[width=\textwidth]{screenshots/dep-eg-1.png}
    \end{center}
\end{minipage}
\caption[Dependency Graph Example 1.]{\small Dependency Graph Example 1.}
\label{fig-dep-eg-1}
\end{figure}

\subsubsection{Graph Syntax}

Multiline graph strings may contain:
\begin{myitemize}
    \item {\bf blank lines}
    \item {\bf arbitrary white space}
    \item {\bf task names}
    \item {\bf arrows} (\lstinline@=>@) for dependencies (triggers)
    \item {\bf comments} - following the \# character
    \item {\bf conditional operators}: \lstinline=&= (AND) and \lstinline=|= (OR)
    \item {\bf explicit task output labels} - \lstinline=foo:fail=, \lstinline=foo:out1=
    \item {\bf cycle time offsets} - \lstinline=A(T-6)=
\end{myitemize}

\subsubsection{Valid Cycle Times For Each Task}

The set of hours at which a task can run is defined by
the hour list headings of any graph sections that the task appears
in. This is how cylc knows what ``the next cycle time'' for a particular
task is, when it comes time to spawn a successor.

\subsubsection{Partitioning The Graph}

Suite dependency graphs can be broken down into {\em dependent pairs}
where the left side of pair (which may be a single task, or several 
that are conditionally related) defines a trigger for the task on the
right, for cycle times matching the list of hours specified for the
graph section.

For instance, the simple ``word graph'' {\em C(T) triggers off B(T) which
triggers off A(T)}, where T represents task cycle time, can be
deconstructed into the pairs {\em C(T) triggers of B(T)} and {\em B(T)
triggers off A(T)}. Also, T should be left implicit except when the left
side has an offset, i.e:
\begin{myitemize}
    \item \lstinline=A(T)= must be written as just \lstinline=A=
\end{myitemize}
This make graphs look clean and concise, because the vast majority of
tasks in a typical suite will only depend on others with the same cycle
time.
        
Also, because dependent pairs define a trigger for the right side task
at cycle time T, where T matches one of the hours listed for the graph
section,
\begin{myitemize}
    \item cycle time offsets such as \lstinline=A(T-6)= can only appear
        on the left side of a pair.
\end{myitemize}

Now, having explained that dependency graphs are interpreted in a
pairwise manner, you can optionally, but intuitively, chain pairs
together to ``follow a path'' through the graph. So this,
\begin{lstlisting}
# SUITE.RC
    graph = """
            A => B  # B triggers off A
            B => C  # C triggers off B
            """
\end{lstlisting}
is equivalent to (and can be written like) this:
\begin{lstlisting}
# SUITE.RC
    graph = """
            A => B => C 
            """
\end{lstlisting}
Note that because cycle time offsets can only appear on the left of an
arrow, any such offset task can only be leftmost in the chain, so this
is legal:
\begin{lstlisting}
# SUITE.RC
    graph = "A(T-6) => B => C"  # OK
\end{lstlisting}
but this isn't:
\begin{lstlisting}
# SUITE.RC
    graph = "A => B(T-6) => C"  # ERROR!
\end{lstlisting}
(Of course \lstinline@A => B(T-6)@ would not make sense in a real suite
in any case - if this kind of relationship seems necessary, it probably
means that B should be ``reassigned'' to the next cycle - remember 
that except for the actual forecast models in a suite, cycle time is
really just a label used to define the relatonships between tasks).

{\em Each trigger in the graph must be unique} but {\em the same task
can appear in multiple pairs or chains}. Separately defined triggers
for the same task have an AND relationship. So this:
\begin{lstlisting}
# SUITE.RC
    graph = """
            A => X  # X triggers off A
            B => X  # X also triggers off B
            """
\end{lstlisting}
is equivalent to (and can be written like) this:
\begin{lstlisting}
# SUITE.RC
    graph = """
            A & B => X  # X triggers off A AND B
            """
\end{lstlisting}

The branching tree structure of a dependency graph can now be
partitioned into lines (in the suite.rc graph string) of pairs
or chains, in any way you like, with liberal use of internal white space
and comments to make the graph structure as clear as possible.

\begin{lstlisting}
# SUITE.RC
# B triggers if A succeeds, then C and D trigger if B succeeds:
    graph = "A => B => C & D"
# which is equivalent to this:
    graph = """A => B => C
            B => D"""
# and to this:
    graph = """A => B
               B => C
               B => D"""
# and it can even be written like this:
    graph = """A => B # blank line follows:

               B => C # comment ...
               B => D"""
\end{lstlisting}

\subsubsection{Task Succeeded Triggers}

This is the default behaviour - to trigger off another that succeeds (i.e.\ {\em finishes successfully}):
\begin{lstlisting}
# SUITE.RC
# B triggers if A SUCCEEDS:
    graph = A => B
\end{lstlisting}

\subsubsection{Task Failed Triggers}

To get a task to trigger off another's failure:
\begin{lstlisting}
# SUITE.RC
# B triggers if A FAILS:
    graph = A:fail => B
\end{lstlisting}

This can be used for certain kinds of failure recovery.
If you don't care whether a task succeeds or fails so
long as it finishes,
\begin{lstlisting}
# SUITE.RC
# B triggers if A either SUCCEEDS or FAILS:
    graph = A | A:fail => B
\end{lstlisting}

\subsubsection{Internal Triggers}

{\em These are only needed if you want a task to trigger early off an
output that the upstream task completes before it finishes.}

\begin{lstlisting}
# SUITE.RC
[dependencies]
    [[6,18]]
        # B triggers off specific OUTPUT "out1" of task A:
        graph = A:out1 => B
[tasks]
    [[A]]
        [[[outputs]]]
            out1 = "NWP products uploaded for $(CYCLE_TIME)"
\end{lstlisting}

Task A must emit this message when the actual output has been completed - 
see {\em Reporting Internal Outputs Completed}, Section~\ref{RIOC}.

\subsubsection{Intercycle Triggers}
\label{IntercycleTriggers}

Most tasks in a typical suite will trigger off other cotemporal (same
cycle time) tasks, but some may depend on tasks with earlier cycle
times. This notably applies to warm cycled forecast models, which depend
on their own previous instances (see below); but more general intercycle
dependence is not uncommon.\footnote{In NWP forecast
analysis suites parts of the observation processing and data
assimilation subsystem will typically also depend on model background
fields generated by the previous forecast.} Here's how to express this
kind of relationship in cylc:
\begin{lstlisting}
# SUITE.RC
[dependencies]
    [[0,6,12,18]]
        # B triggers off A in the previous cycle
        graph = "A(T-6) => B"
\end{lstlisting}

This notation can be used with explicit outputs too:
\begin{lstlisting}
# SUITE.RC
    # B triggers if A in the previous cycle fails:
    graph = "A(T-6):fail => B"
\end{lstlisting}
 
\subsubsection{Conditional Triggers}

AND operators (\lstinline=&=) can appear on both sides of an arrow. They
provide a concise alternative to defining multiple triggers separately:
\begin{lstlisting}
# SUITE.RC
# 1/ this:
    graph = "A & B => C"
# is equivalent to:
    graph = """A => C
            B => C"""
# 2/ this:
    graph = "A => B & C"
# is equivalent to:
    graph = """A => B
            A => C"""
# 3/ and this:
    graph = "A & B => C & D"
# is equivalent to this:
    graph = """A => C
            B => C
            A => D
            B => D"""
\end{lstlisting}

OR operators (\lstinline=|=), for true ``conditional triggers'',
can only appear on the left,\footnote{An OR
operator on the right doesn't make much sense in the context of a
forecasting suite: if ``B or C'' triggers off A, what exactly should
cylc do when A finishes?}
\begin{lstlisting}
# SUITE.RC
# C triggers when either A or B finishes:
    graph = "A | B => C"
\end{lstlisting}

\paragraph{Which Task Will Be Plotted?}

In a list of alternative triggers separated by OR operators, the 
full conditional expression determines run time behaviour, but one of
the alternatives has to be singled out in order to plot the graph: the
rightmost task is plotted by default; to change this change the task
order or attach an asterisk to the chosen task:
\begin{lstlisting}
# SUITE.RC
# this will plot as C => D:
    graph = "A | B | C => D"
# but this will plot as A => D:
    graph = "A* | B | C => D"
\end{lstlisting}

In future cylc releases we may allow all tasks in a conditional trigger
to be plotted, with dotted arrows, say, to indicate the conditional nature
of the relationship.

% TO DO: !!!!! GRAPHING BUG FOR A | B & C EXPRESSIONS!!!!!!!!

\paragraph{Complex Conditional Triggers With AND And OR}

You can use AND and OR operators in the same expression, 
\begin{lstlisting}
# SUITE.RC
    # D triggers if (A) or (both B and C) succeed:
    graph = "A | B & C => D" 
\end{lstlisting}

{\em KNOWN BUG ALERT: complex conditional triggers work as expected in 
cylc suites at run time, but they are currently not graphed properly.}

\paragraph{Parenthesized Complex Conditional Triggers}

{\em Parenthesized conditional expressions are currently illegal.}
Internally cylc can handle this perfectly well, because it transforms 
prerequisite conditions directly into Python code and gets the 
interpreter to evaluate the result, {\em but} the cylc-3 suite.rc graph
parser currently cannot handle general conditional expressions.

This restriction should not be an impediment because forecasting suites
tend to have simple requirements for conditional triggers (plus you can
rely on operator precedence - AND before OR - and split large
expressions into multiple lines). However, if there is any call for more
complicated conditional triggers we will certainly address this problem.

\subsubsection{Satisfying Intercycle Dependencies At Startup}
\label{SatisfyingIntercycleDependenciesAtStartup}

Considering the intercycle dependence shown in {\em Intercycle Triggers}
(Section~\ref{IntercycleTriggers}) it is clear that some kind of
bootsrapping process will be required to get the suite going initially,
because in the very first cycle there is no previous instance of A to
satisfy B's prerequisites. 
 
\paragraph{Cold Start Tasks}

A {\em cold start task} is a special one off task used to satisfy the
initial previous-cycle dependence of another cotemporal task. In effect, 
the cold start task masquerades as its counterpart's previous-cycle trigger. 

A cold start task may invoke real processing (to generate the files that
are normally generated by the cycling task that it masquerades as) or it
could be a dummy task that represents some external spinup process
(resulting in the same files) that has to be completed before the suite
is started (in this case the cold start task in cylc will just report
itself successfully completed, thereby satisfying the aforementioned
dependencies).

This kind of relationship can easily be expressed with a conditional
trigger:
\begin{lstlisting}
# SUITE.RC
[special tasks]
    cold start = ColdFoo
[dependencies]
    [[0,6,12,18]]
        graph = "ColdFoo | Bar(T-6) => Foo"
\end{lstlisting}
In other words, Foo(T) can trigger off {\em either} Bar(T-6) {\em or} 
ColdFoo(T). At startup ColdFoo will do the job, before being be eliminated 
from the suite (because cold start tasks are non-spawning), and
thereafter Bar(T-6) will do it.

{\em A cold task can also be inserted into the suite at run time 
to cold start just the task that it is associated with, if a problem of 
some kind prevents continued normal cycling}.

\paragraph{Warm Starting A Suite}

Cold start tasks have to be declared as such in the suite.rc ``special
tasks'' section so that cylc knows they are one off (non-spawning) tasks,
but also because they play a critical role in suite warm starts.

{\em Warm starting} a previously shut down suite at a particular cycle
time is an alternative to {\em restarting} it from a previous state
(which in cylc is likely to include tasks with several different
cycle times). Warm starts assume the existence of a previous cycle
(i.e.\ that any files from the previous cycle that are required by the
new cycle will be in place already). So no cold start tasks need to run
{\em but} cylc itself doesn't know the details of the previous cycle (it
would if you did a restart from the previous state rather than a warm
start) so it still has to solve the bootstrapping problem to get the
suite started. It does this by starting the suite with designated cold
start tasks already in the succeeded state. In other words, the cold
start tasks stand for the previous finished cycle, rather than actually
running processes that masquerade as the previous cycle.

\subsubsection{Model Restart Dependencies}
\label{ModelRestartDependencies}

Warm cycled forecast models generate {\em restart files}, e.g.\ model
background fields, that are required to initialize the next forecast
(this is essentially the definition of ``warm cycling''). In fact
restart files will often be written for a whole series of subsequent
cycles in case the next cycle (or the next and the next-next, and so on)
cycle has to be omitted: 
\begin{lstlisting}
# SUITE.RC
[special tasks]
    sequential = A
[dependencies]
    [[0,6,12,18]]
        # Model A cold start and restart dependencies:
        graph = """
   ColdA | A(T-6) | A(T-12) | A(T-18) | A(T-24) => A
                """
\end{lstlisting}
In other words, task A can trigger off its cold start task, {\em or} off
its own previous instance, {\em or} the instance before that, and so on.
Restart dependencies are unusual because although A {\em could}
trigger off A(T-12) we don't actually want it to do so unless A(T-6)
fails and can't be fixed. {\em This is why Task A, above, is declared to be
`sequential'}.\footnote{A warm cycling model that only writes out
one set of restart files, for the very next cycle, does not need to be
declared sequential because this early triggering problem cannot arise.}
Sequential tasks do not spawn a successor until they have
succeeded (by default, tasks spawn as soon as they start running in
order to get maximum functional parallelism in a suite) which
means that A(T+6) will not be waiting around to trigger off an older
predecessor while A(T) is still running. If A(T) fails though, the
operator can force it, on removal, to spawn A(T+6), whose restart
dependencies will then automatically be satisfied by the older instance,
A(T-6). 

Forcing a model to run sequentially means, of course, that its restart
dependencies cannot be violated anyway, so we might just ignore them.
This is certainly an option, but it should be noted that there are some 
benefits to having your suite reflect all of the real dependencies
between the tasks that it is managing, particularly for complex
multi-model operational suites in which the suite operator might not be
an expert on the models. Consider such a suite in which a failure in a
driving model (e.g.\ weather) precludes running one or more 
cycles of the downstream models (sea state, storm surge, river flow,
\dots). If the real restart dependencies of each model are known to the
suite, the operator can just do a recursive purge to remove the subtree
of all tasks that can never run due to the failure, and then cold start
the failed driving model after a gap (skipping as few cycles as possible
until the new cold start input data are available). After
that the downstream models will kick off automatically so long as the 
gap is spanned by their respective restart files, because their
restart dependencies will automatically be satisfied by the older
pre-gap instances in the suite. Managing this kind of scenario manually
in a complex suite can be quite difficult.

Finally, if a warm cycled model is declared in `models with explicit
restart outputs', instead of `sequential' tasks, and you use explicit
labeled restart outputs {\em containing the word `restart'}, then 
the task will spawn as soon its last restart output is completed so 
that successives instances of the task will be able to overlap (i.e.\
run in parallel) if the opportunity arises. Whether or not this is worth
the effort depends on the situation, of course.

\begin{lstlisting}
# SUITE.RC
[special tasks]
    models with explicit restart outputs = A
[dependencies]
    [[0,6,12,18]]
        graph = """
  ColdA | A(T-18):res18 | A(T-12):res12| A(T-6):res6 => A
                """
[tasks]
    [[A]]
        [[[outputs]]]
            r6  = restart files completed for $(CYCLE_TIME+6)
            r12 = restart files completed for $(CYCLE_TIME+12)
            r18 = restart files completed for $(CYCLE_TIME+18)
\end{lstlisting}


\subsubsection{Task Families}
\label{TaskFamilies}

A task family is a named group of tasks that appears as a single task
in the suite dependency graph. Instead of having each individual member
task trigger off one or more upstream tasks, you can just trigger the
family; and instead of triggering downstream processing off each member task, 
you can trigger off the family as a whole.

\begin{myitemize}
    \item a family enters the `running' state when its prerequisites are
        satisfied
        \begin{myitemize}
            \item this causes each member of the family to trigger
        \end{myitemize}
    \item a family's final state is not determined until all of its
        members have succeeded or failed:
        \begin{myitemize}
            \item succeeded, if all members succeeded
            \item failed, if one or more members failed   
        \end{myitemize}
\end{myitemize}

Cylc task families are implemented as special pseudo-tasks that do not
actually submit anything to run when they enter the `running' state.

Cylc task families can have internal dependencies, and members can also
participate in dependent relationships outside of the family.

Task families can be declared `sequential' in the suite.rc [special
tasks] section, in which case they will run sequentially even if
their members are not sequential.

To trigger downstream processing off a family even if one or more of its 
members failed (e.g.\ a family of obs processing tasks wherein you want
to use the obs that were successfully processed even if some members 
fail) use a conditional trigger on the family:

\begin{lstlisting}
# SUITE.RC
[dependencies]
    [[ 0,6,12,18 ]]
        graph  =  "Family | Family:fail => PostProc"
\end{lstlisting}

Task families are listed in the top level of the suite.rc file, and 
then used in the suite graph just like ordinary tasks.

\begin{lstlisting}
# SUITE.RC
[task families]
    Family = one, two, three, four
[dependencies]
    [[ 0,6,12,18 ]]
        graph  =  "PreProc => Family => PostProc"
[visualization]
    show family members = True
    default node attributes = "shape=box", "color=black"
\end{lstlisting}

This simple suite is plotted, with and without family members, in
Figure~\ref{fig-fam-eg-3}.

\begin{figure}
\begin{minipage}[t]{0.4\textwidth}
    \begin{center}
        \includegraphics[width=0.4\textwidth]{screenshots/family-one.png}
    \end{center}
\end{minipage}
\hfill
\begin{minipage}[t]{0.6\textwidth}
    \begin{center}
        \includegraphics[width=0.6\textwidth]{screenshots/family-two.png}
    \end{center}
\end{minipage}
\caption[A simple task family]{\small A very small suite with
a simple task family, showing the family itself on the left, and the
effective dependencies on the right (plotted with
\lstinline@SUITE.RC: [visualization] -> show family members = True@).}
\label{fig-fam-eg-3}
\end{figure} 

\paragraph{Recovering From Task Family Failures} 

If a family member fails it will enter the `failed' state, and once 
all other members have finished (succeeded or failed), the family itself
will enter the failed state. To recover from this, assuming the problem
that caused the original member to fail is fixable,

\begin{myenumerate}
    \item fix the problem that caused the failure
    \item reset the failed member task to the `waiting' state
    \item retrigger the family itself
\end{myenumerate}
When the family triggers, the reset member task will follow suit. If the
member completes successfully this time, so will the family,
and downstream processing will proceed as normal.

\paragraph{Use Task Families Sparingly}

Task families should really only be used as a convenient simplification
for groups of tasks that would naturally trigger at the same time anyway
(e.g.\ multiple tasks for processing different types of observations
that are all made available at the same time) and whose outputs would
all be put to use at a similar time too. Otherwise use of task families
may unnecessarily constrain cylc's ability to achieve maximum functional
parallelism, because every member has to wait on its parent family 
starting before it can run, and all members have to finish before
downstream processing can continue.\footnote{Actually downstream tasks
can trigger off individual family members as if they weren't family
members - but extensive use of this would probably defeat the purpose 
of using a family in the first place.}

\subsection{Task Definition}
\label{Task Definition}

A task's position in the suite dependency graph determines its
relationship to other tasks and its valid cycle times. Other
properties such as execution environment and the command scripting
used to invoke task processing are defined under the suite.rc 
\lstinline=[tasks]= section.

Note that there is not necessarily a one-to-one mapping between tasks
defined in the suite.rc file and the external commands, scripts, or
programs that implement them. Multiple tasks can call the same script
(etc.) with varying inputs supplied by their respective command lines
and execution environments.

\subsubsection{A Task Definition Example}
\label{ATaskDefinitionExample}

The following rather trivial suite of two tasks illustrates the important
aspects of task definition:

\begin{lstlisting}
# SUITE.RC
title = "A two task test suite"
description = "Used as an example in Section 7.4 of the User Guide"
[dependencies]
    [[0,12]]              # For cycle times ending in 00 and 12 hours
        graph = "A => B"  # B triggers when A successfully finishes
[environment]             # GLOBAL ENVIRONMENT
    NEXT_CYCLE = $( cylc util cycletime -a 12 )
    PREV_CYCLE = $( cylc util cycletime -p 12 )
[tasks]
    [[A]]                 # TASK A PROPERTIES
        description = "Task A, does something"
        command = A.sh
        [[[environment]]] # Task A environment
            INPUT = foo-${NEXT_CYCLE}.txt
    [[B]]                 # TASK B PROPERTIES
        description = "Task B, does something else"
        command = B.sh -f
        [[[environment]]] # Task B environment
            INPUT = bar-${NEXT_CYCLE}.txt
\end{lstlisting}

Note the task names in the suite dependency graph, the command scripting
for each task, and the global and task-specific environment sections.

\subsubsection{Task Names}
\label{TaskName}

Task names can contain letters, digits, and underscores. Task names
should not be hard wired into task implementations (scripts, models,
etc.) because task and suite identity can be extracted portably from the
task execution environment supplied by the suite
(Section~\ref{TaskExecutionEnvironment}) - then to rename a task, just
change the name in the suite.rc file.

\subsubsection{Task Execution Environment}
\label{TaskExecutionEnvironment}

The task execution environment comprises variables automatically 
defined by cylc, and global and task-specific variables defined 
in the suite.rc file. These variables are explicitly exported 
prior to executing the task command scripting (to see how this
is implemented go to Section~\ref{TaskExecution}, {\em Task
Execution}).  

\paragraph{Suite And Task Identify}
\label{SATI}

The task's name and cycle time are defined before the global variables,
so global variables can actually be made task- and cycle-specific by
referencing them. 

An executing task will almost certainly need to use its own cycle time:
\begin{lstlisting}
$CYCLE_TIME    
\end{lstlisting}
It may also need the location of its suite definition
directory, to access files stored there,
\begin{lstlisting}
$CYCLE_SUITE_DIR
\end{lstlisting}
And it may need to use the task and suite identity variables (e.g.\ to 
make portable suites that write all output to suite-specific locations):
\begin{lstlisting}
$CYLC_SUITE            # e.g. foo:bar
$CYLC_SUITE_GROUP      # foo
$CYLC_SUITE_NAME       # bar 
$TASK_NAME             # X
$TASK_ID               # X%2011051118
\end{lstlisting}

These variables are also used automatically by the cylc task messaging
commands, to target the right task proxy object in the right suite.

\paragraph{Task Access To Cylc}

Task execution environments are automatically configured to give the
executing task access to cylc commands and utilities. This is done prior
to exporting user-defined variables so that cylc utility commands can
be used in variable assignment expressions. For example: 
\begin{lstlisting}
# SUITE.RC
[environment]
    FOO = $( cylc util cycletime --add=6 )
\end{lstlisting}

\paragraph{Global And Task-Specific Environment Variables}

Generally speaking, parameters common to several tasks should be defined
once in the global environment section of the suite.rc file; and those
needed by a single task, in the task-specific environment section.
Task-specific variables can reference global variables.

Order of definition is preserved for user-defined global and
task-specific environment variables, so you can safely refer to
previously defined variables.

\paragraph{When Are Environment Variables Evaluated?}

Environment variables are {\em not} evaluated by cylc prior to executing
the task. They are written, in unevaluated form, to the job script that
is submitted by cylc to run the task (this is shown in
Section~\ref{JobScripts}). Thus \lstinline=$HOME=, for instance, will
evaluate, at run time, to the home directory of the account under which
the task executes (which isn't necessarily the same account, or even the
same host, that is running the suite). 

%\paragraph{Global Pre- and Post-Command Scripting}
%
%The global {\em pre-} and {\em post-command scripting} suite.rc items
%(not shown in the example job script above) are multiline strings
%containing scripting to be executed verbatim immediately before
%and after the task command scripting, for every task (task-specific 
%scripting goes in the task command scripting (or in an external script
%invoked by it).

%\pagebreak

%\paragraph{Error Trapping}
%
%This line:
%\begin{lstlisting}
%set -e; trap 'cylc task failed "Error trapped by task job script"' ERR
%\end{lstlisting}
%results in the suite being informed of task failure if any command 
%in the job script fails. Any external scripts invoked in the task
%command scripting must likewise return non-zero exit status on error
%in order to trigger the trap.

\subsection{Suite Validation}
\label{Validation}

Suite validation is designed to catch most suite definition errors
before run time.  First the suite.rc file is validated
against the spec file \lstinline=$CYLC_DIR/conf/suiterc.spec=, which 
is the ultimate arbiter of what's legal in a cylc suite definition
(see the {\em Suite.rc Reference}, Appendix~\ref{SuiteRCReference}).
Validation detects any formatting
errors, typographic errors, illegal items, and illegal values; then some
global consistency checking is done; and finally the validator attempts
to create each suite task proxy according to information parsed from the
suite.rc file.

Here's an example of a successful validation,
\begin{lstlisting}
$ cylc validate examples:simple
Parsing Suite Config File
Instantiating Task Proxies:
  -  ColdModel ... OK
  -  GetData ... OK
  -  Model ... OK
  -  PostA ... OK
  -  PostB ... OK
  -  Prep ... OK
Suite examples:simple validates OK.
DONE
\end{lstlisting}

\subsubsection{Validation Errors}

The validator reports the line numbers of detected errors. 

\begin{lstlisting}
$ cylc validate examples:simple
Parsing Suite Config File
ERROR: [[special tasks]
NestingError('Cannot compute the section depth at line 19.',)
_validate examples:simple  failed:  1
\end{lstlisting}

If the suite.rc file contains include-files, use the 
\lstinline=cylc inline SUITE= command (or the gcylc 
right-click `Edit' option) to view an inlined copy with correct line
numbers.

\subsubsection{Validation Warnings}

Warnings are emitted by the validator if any tasks in the dependency
graph are not defined in the [tasks] section, or if any tasks defined in
the [tasks] section are not used in the dependency graph:
\begin{lstlisting}
Parsing Suite Config File
WARNING: task "PostA" is defined only by graph: it will run as a dummy task.
WARNING: task "Prep" is defined in [tasks] but not used in the graph.
Instantiating Task Proxies:
  -  ColdModel ... OK
  -  GetData ... OK
  -  Model ... OK
  -  PostA ... OK
  -  PostB ... OK
  -  Prep ...WARNING: no hours in graph or [tasks][[Prep]]; task can be 
                      'submit'ed but not inserted into the suite.
 OK
Suite examples:simple validates OK.
DONE
\end{lstlisting}
These are not necessarily errors - a task defined by graph alone will
run as a dummy task, and you can temporarily disable a defined task by
commenting it out of the dependency graph. 

\section{Task Implementation}
\label{TaskImplementation}

This section lays out the minimal requirements on external commands,
scripts, or executables invoked by cylc to carry out task processing.

\subsection{Most Tasks Require No Modification For Cylc}

Any existing command, script, or executable can function as a cylc task
if the following conditions are met:
\begin{myitemize}
    \item The task must have no {\em internal outputs} that others trigger
        off - otherwise it must be modified to report when those
        internal outputs are completed.
    \item The script or process that invokes the task must not exit before 
        all task processing is finished - otherwise it must be modified to
        report final success or failure itself.
    \item Task scripting must return non-zero exit status on error, to
        allow automatic detection of successful completion or failure.
\end{myitemize}

If these requirements are not met see {\em Modifying Scripts For Cylc},
Section~\ref{TaskModsForCylc}. Reporting internal outputs is easy.
Manual completion messaging is more involved, but is typically only
needed for large models with internally complex native job submission
processes.

The following suite.rc listing shows several tasks that run external 
scripts, \lstinline=foo.sh= and \lstinline=bar.sh=, which do not 
know about cylc:
\begin{lstlisting}
# SUITE.RC
[tasks]
    [[foo]]
        description = a task that runs foo.sh
        command = foo.sh OPTIONS ARGUMENTS

    [[bar]]
        description = a task that runs bar.sh
        command = """echo HELLO
                     bar.sh
                     echo BYE""" 

    [[baz]]
        description = "a task that runs baz.sh, and retries on failure"
        command = """echo attempt No.1
                     baz.sh""",
                  """echo attempt No.2  # only invoked if try No.1 fails
                     baz.sh --retry"""
\end{lstlisting}

\subsection{Suite.rc Inlined Tasks}

Simple tasks can be entirely implemented within the suite.rc file
because the task {\em command} string can contain multiple lines
of scripting (or a list of such strings, to retry on failure). The
command string is written verbatim to the task job script after 
configuring the execution environment - see {\em Task Execution},
Section~\ref{TaskExecution}.


\subsection{Return Non-zero Exit Status On Error}

The requirement to abort with non-zero exit status on error
(which should be normal scripting practice in any case) 
allows the job script to trap errors and send a 
\lstinline=cylc task failed= message to alert the suite.  You can 
use \lstinline=set -e= to avoid writing explicit error checks for every
operation:

\begin{lstlisting}
#!/bin/bash
set -e  # abort on error
mkdir /illegal/dir  # this error will abort the script with non-zero exit status
\end{lstlisting}

\subsection{Modifying Scripts For Cylc}
\label{TaskModsForCylc}

\subsubsection{Voluntary Messaging}

If you like you can modify task scripts to log explanatory messages with
the suite if certain events occur. For example, a task can send a
priority critical message before aborting on error:

\begin{lstlisting}
#!/bin/bash
set -e  # abort on error
if ! mkdir /illegal/dir; then
    # (use inline error checking to avoid triggering the above 'set -e')
    cylc task message -p CRITICAL "Failed to create directory /illegal/dir"
    exit 1 # now abort non-zero exit status to trigger the task failed message
fi
\end{lstlisting}

You can also use this syntax:
\begin{lstlisting}
#!/bin/bash
set -e
mkdir /illegal/dir || {  # inline error checking using OR operator
    cylc task message -p CRITICAL "Failed to create directory /illegal/dir"
    exit 1
}
\end{lstlisting}

But not this:
\begin{lstlisting}
#!/bin/bash
set -e
mkdir /illegal/dir  # aborted via 'set -e'
if [[ $? != 0 ]]; then  # so this will never be reached.
    cylc task message -p CRITICAL "Failed to create directory /illegal/dir"
    exit 1
fi
\end{lstlisting}

You can also send warning messages, or general information:
\begin{lstlisting}
#!/bin/bash
# a warning message (this will be logged by the suite):
cylc task message -p WARNING "oops, something's fishy here"
# information (this will also be logged by the suite):
cylc task message "Hello from task foo"
\end{lstlisting}

This may be useful - any message received from a
task is logged by cylc - but it is not a requirement.  If error messages
are not reported, for instance, task failure will still be registered,
and task stdout and stderr can be examined for evidence of what went
wrong.

\subsubsection{Reporting Internal Outputs Completed}
\label{RIOC}

Tasks with internal outputs that allow downstream processing to
trigger before they are finished must report when those internal outputs
have been completed:

\begin{lstlisting}
#!/bin/bash
# (task foo implementation)
# ...
# report an output completed:
cylc task message "foo products uploaded for $CYCLE_TIME"
\end{lstlisting}
This must match one of the task's registered outputs:
\begin{lstlisting}
# SUITE.RC
[dependencies]
    [[6,18]]
        graph = foo:output1 => bar
[tasks]
    [[foo]]
        output1 = "foo products uploaded for $(CYCLE_TIME)"
\end{lstlisting}
otherwise it will just be logged as a progress report or similar.

\subsubsection{Tasks With Initiating Processes That Detach And Exit Early}

Tasks with initiating scripts or processes that spawn jobs internally
(e.g.\ to a batch queue scheduler or to another host) and then
detach and exit without seeing the resulting processing through 
must arrange for the spawned processing to send its own ``cylc
task succeeded'' or ``cylc task failed'' messages on completion -
because the cylc-generated job script (Section~\ref{JobScripts}) that
otherwise provides automatic completion messaging cannot know when 
the task is really finished. To disable automatic completion messaging:

\begin{lstlisting}
# SUITE.RC
manual task completion messaging = True  # global setting
[tasks]
    [ [foo]]
        manual task completion messaging = True  # task-specific setting
\end{lstlisting}

Reporting success or failure is just a matter of calling the cylc
messaging commands:
\begin{lstlisting}
#!/bin/bash
# ...
if $SUCCESS; then
    # release my task lock and report success
    cylc task succeeded
    exit 0
else
    # release my task lock and report failed
    cylc task failed "Input file X not found"
    exit 1
fi
\end{lstlisting}

Bear in mind, however, that cylc messaging commands read environment
variables that identify the calling task and the target suite, as
explained in {\em Task Execution Environment}
(Section~\ref{TaskExecutionEnvironment}), so if your job submission
method does not automatically copy its parent environment you must
arrange for these variables, at the least, to be propagated through to
your spawned sub-jobs.

One way to handle this is to write a {\em task wrapper} that modifies a
copy of the detaching native job scripts, on the fly, to insert
completion messaging in the appropriate places, and other variables if
necessary, before invoking the (now modified) native process. A
significant advantage of this method is that you don't need to
permanently modify the model or its associated native scripting 
for cylc. Another is that you can configure the native job setup 
for a single test case (running it without cylc) and then have 
your custom wrapper modify the test case on the fly with suite, task,
and cycle-specific parameters as required.

To make this easier, for tasks that declare manual completion 
messaging, cylc makes non user-defined environment scripting
available in a single variable called
\lstinline=$CYLC_SUITE_ENVIRONMENT= that can be inserted into the
aforementioned native task scripts prior to calling the cylc messaging
commands.\footnote{Note that \lstinline=$CYLC_SUITE_ENVIRONMENT= is 
a string containing embedded newline characters and it has
to be handled accordingly. In the bash shell, for instance, it should
be echoed in quotes to avoid concatenation to a single line.}

\subsubsection{A Custom Task Wrapper Example}

The example suite {\bf examples:detach} contains a script 
\lstinline=model.sh= that runs a pseudo-model executable as follows:
\lstinputlisting{../examples/detach/native/model.sh}
this is in turn executed by a script \lstinline=run-model.sh= that
detaches immediately after job submission (i.e.\ it exits before the
model executable actually runs):
\lstinputlisting{../examples/detach/native/run-model.sh}
{\em Note that your {\bf at} scheduler daemon must be up 
if you want to test this suite.}

Here's a cylc suite to run this unruly model:
\lstinputlisting{../examples/detach/suite.rc}

The suite invokes the task by means of the custom wrapper 
\lstinline=model-wrapper.sh= which modifies, on the fly, 
a temporary copy of the model's native job scripts as described above:
\lstinputlisting{../examples/detach/bin/model-wrapper.sh}

If you run this suite, or submit the model task alone with
\lstinline=cylc submit=, you'll find that the usual job submission 
log files for task stdout and stderr end before the task is finished. 
To see the ``model'' output and the final task completion message
(success or failure), examine the log files generated by the 
job submitted internally to the {\em at} scheduler (their 
location is determined by the \lstinline=$PREFIX= variable in the
suite.rc file). 

It should not be difficult to adapt this example to real tasks
with detaching internal job submission.  You will probably also need to
replace other parameters, such as model input and output filenames, with
suite- and cycle-appropriate values, but exactly the same technique can
be used: identify which job script needs to be modified and use text
processing tools (such as the single line {\em perl} search-and-replace 
expressions above) to do the job.

\subsection{Running Local Tasks Under Other User Accounts}

If a task declares an owner other than the suite owner, and does not
declare a remote host:
\begin{lstlisting}
# SUITE.RC
owned task execution method = sudo  # or ssh
[tasks]
    [[foo]]
        owner = bob
        job submission method = loadleveler
\end{lstlisting}
cylc will attempt to execute the task, by the configured 
{\em job submission method} (e.g.\ loadleveler), as the specified owner,
using the configured {\em owned task execution method}. To use sudo 
with llsubmit (loadleveler), for example, \lstinline=/etc/sudoers= must
be configured to allow the suite owner to execute the llsubmit command
as the task owner.  For ssh, passwordless ssh must be configured between
the suite owner and task owner accounts.

{\em A task owner can also be declared globally, if all or most of your
tasks need to run under a different username than the suite owner.}

\subsection{Running Tasks On A Remote Host}
\label{RunningTasksOnARemoteHost}

{\em You should not need this functionality if you have a cross-platform
resource manager, such as loadleveler, that allows you to submit a job
locally to run on the remote host}.

If a task declares a remote host and owner in its suite.rc task section,
cylc will copy the task job script to the remote host by
\lstinline=scp=, and then run it on the remote host (using the
right job submission method for the task) by \lstinline=ssh=. 

{\em Remote host, task owner, and directories can be declared globally
and/or by task. Use the global settings if all or most of your tasks
need to run on the same remote host}.

\begin{lstlisting}
# SUITE.RC

# GLOBAL remote host settings
owner = alice
remote host = foo.niwa.co.nz
remote cylc directory = /path/to/remote/cylc/installation/on/foo
remote suite directory = /path/to/remote/suite/definition/on/foo
job submission method = loadleveler
[tasks]
    [[TaskA]]
        # (no task specific remote host settings: this task runs on foo)
        # ...
    [[TaskB]]
        # TASK remote host settings:
        owner = bob
        remote host = bar.niwa.co.nz  # but this one runs on bar
        remote cylc directory = /path/to/remote/cylc/installation/on/bar
        remote suite directory = /path/to/remote/suite/definition/on/bar
        job submission method = at_now
\end{lstlisting}

Specifying the remote cylc directory gives remote tasks access 
to cylc commands; and the remote suite directory gives them 
access to suite files via \lstinline=$CYLC_SUITE_DIR=, and to the
suite bin directory via \lstinline=$PATH= (automatically configured by
the cylc environment script).

\begin{myitemize}
    \item passwordless ssh must be configured between the suite owner on
        the suite host and the task owner on the remote host.
    \item cylc (and Pyro) must be installed on the remote host, so that
        the remote task can communicate with its parent suite.
    \item the suite definition directory must be installed on the remote
        host, if the task needs access to scripts in the suite bin
        directory or to any other files stored there.
\end{myitemize}

{\em Note that you can easily run the cylc example suites on a remote
host by simply setting the global remote hosting suite.rc configuration
items} (if cylc is installed on the remote host). For the
example suites with real task implementations that work with ``real''
files, you'll have to run {\em all} tasks on the same remote host so
that they can all access their required input and output files. To
distribute a suite across several hosts you must arrange (using
additional tasks) to transfer files between the hosts as required to
satisfy the real I/O dependencies.

\subsubsection{Remote Task Log Directories}

The stdout and stderr from local tasks is directed into files in the
{\em job submission log directory} (specified in the suite.rc file) 
as explained in Section~\ref{WhitherStdoutAndStderr}. 

{\em Remote task stdout and stderr, however, currently ends up in the 
remote task owner's home directory}, ignoring any suite.rc job log
directory settings. This is simply because at cylc's home institution
we now have cross platform job submission via loadleveler so we don't
need cylc's remote task functionality \dots and consequently cylc 
needs updating slightly in this respect.
        
%\pagebreak

\section{Task Execution}
\label{TaskExecution}

{\em Task Implementation} (Section~\ref{TaskImplementation}) describes
what requirements a command, script, or program, must fulfill in order
to function as a cylc task.

This section explains how tasks are executed when they are ready to
run, and how to define new task job submission methods.

\subsection{Task Job Scripts}
\label{JobScripts}

When a task is ready to run cylc generates a temporary {\em task job
script} to configure the execution environment and call the task's
command scripting. The job script is then submitted to run by
means of the {\em job submission method} specified for the task. 
Different tasks can have different job submission methods. You can set a
default for the suite and override it, if necessary, per task:
 
\begin{lstlisting}
# SUITE.RC
job submission method = loadleveler  # suite default
[tasks]
   [[foo]]
        job submission method = at_now  # just for task foo
\end{lstlisting}

The actual command line used to submit the job script is written to suite 
stdout by cylc. You can see this using \lstinline=cylc submit=, which
runs a single task exactly as the suite would. The \lstinline=--dry-run=
option causes it to generate the job script for inspection and show how
it would be executed with the chosen job submission method. The
following listing illustrates using the two task example suite of
Section~\ref{ATaskDefinitionExample} (also registered as {\em
examples:CUG74} in the central suite database):

\begin{lstlisting}
% cylc submit --dry-run examples:CUG74 A%2011052400
DRY RUN: create the task job script and show how it would be executed.
 > TASK JOB SCRIPT: /tmp/cylc-A%2011052400-jfHtqy
 > JOB SUBMISSION: /tmp/cylc-A%2011052400-jfHtqy </dev/null 1>
     /home/oliverh/CylcJobLogs/examples/CUG74/A%2011052400-DuaPUt.out 2>
     /home/oliverh/CylcJobLogs/examples/CUG74/A%2011052400-DuaPUt.err &
\end{lstlisting}

Here is the generated job script:

\begin{lstlisting}
% cat /tmp/cylc-A%2011052400

#!/bin/bash

# ++++ THIS IS A CYLC TASK JOB SCRIPT ++++
# Task: A%2011052400
# To be submitted by method: 'background'

echo "TASK JOB SCRIPT STARTING"

# CYLC LOCATION, SUITE LOCATION, SUITE IDENTITY:
export CYLC_DIR="/home/oliverh/cylc"
export CYLC_MODE="submit"
export CYLC_SUITE_HOST="oliverh-33191VL.greta.niwa.co.nz"
export CYLC_SUITE_PORT="NONE"
export CYLC_SUITE_DIR="/home/oliverh/cylc/examples/CUG7.4"
export CYLC_SUITE="examples:CUG74"
export CYLC_SUITE_GROUP="examples"
export CYLC_SUITE_NAME="CUG74"
export CYLC_SUITE_OWNER="oliverh"
export CYLC_USE_LOCKSERVER="True"
export CYLC_LOCKSERVER_PORT="7767"
export CYLC_SIMULATION_SLEEP="10"

# TASK IDENTITY:
export TASK_ID=A%2011052400
export TASK_NAME=A
export CYCLE_TIME=2011052400

# ACCESS TO CYLC:
. $CYLC_DIR/environment.sh

# SET ERROR TRAPPING:
set -u # Fail when using an undefined variable
# Define the trap handler
HANDLE_TRAP() {
  echo Received signal "$@"
  cylc task failed "Task job script received signal $@"
  trap "" EXIT
  exit 0
}
# Trap any signals which could cause the script to exit
trap "HANDLE_TRAP EXIT" EXIT
trap "HANDLE_TRAP ERR"  ERR
trap "HANDLE_TRAP TERM" TERM
trap "HANDLE_TRAP XCPU" XCPU

# SEND TASK STARTED MESSAGE:
cylc task started || exit 1

# GLOBAL VARIABLES:
NEXT_CYCLE="$( cylc util cycletime -a 12 )"
PREV_CYCLE="$( cylc util cycletime -p 12 )"
export NEXT_CYCLE PREV_CYCLE

# LOCAL VARIABLES:
INPUT="foo-${NEXT_CYCLE}.txt"
export INPUT

# TASK COMMAND SCRIPTING:
A.sh

# SEND TASK SUCCEEDED MESSAGE:
cylc task succeeded
trap "" EXIT

echo "JOB SCRIPT EXITING (TASK SUCCEEDED)"

#EOF

\end{lstlisting}


\subsection{Available Methods}
\label{AvailableMethods}

\lstset{language=bash}

There are two basic methods that should be available on any platform,
sufficient for running cylc's example suites if not real forecasting
systems:

\begin{myitemize}

    \item \lstinline=background= - run tasks directly in a background shell.

     \item \lstinline=at_now= - submit tasks to the rudimentary
         \lstinline=at= scheduler (\lstinline=atd= must be running).

\end{myitemize}

Tasks in a real forecasting system should be submitted to a batch queue
scheduler or cross-platform resource manager such as {\em loadleveler}
(IBM). Methods currently available are:

\begin{myitemize} 
    
    \item \lstinline=loadleveler= - This method submits general
        (non loadleveler-specific) task scripts to loadleveler. 
        Any {\em directives} you provide in the 
        suite.rc file 
        will be written to the job script, which will then 
        be submitted to run via \lstinline=llsubmit=. 

    \item \lstinline=ll_raw= - This method submits loadleveler-ready
        scripts (i.e.\ scripts containing hardwired directives) to
        loadleveler.  This may be necessary for complex (e.g.\
        multi-step) jobs. The original script is copied to
        make the temporary job script, and cylc environment
        scripting is inserted into it immediately after the loadleveler
        directives.

    \item \lstinline=ll_ecox= - This is derived from the basic 
        \lstinline=loadleveler= method. It automatically adapts certain
        task parameters (such as owner username) to NIWA's EcoConnect
        operational environment so that the same suite definition
        can be used in distinct {\em oper}, {\em test,} and {\em devel}
        environments in which the suite and task owners, and their home
        directories, vary accordingly.

\end{myitemize}


\subsection{Whither Task stdout And stderr?}
\label{WhitherStdoutAndStderr}

When a task is ready to run cylc generates task-specific stdout and
stderr filenames containing the task name, cycle time, and a random
component so that rerunning the task won't overwrite the old output,
e.g.:

\begin{lstlisting}
ColdB%2011101300-N3pBYv.out
ColdB%2011101300-N3pBYv.err
\end{lstlisting}

You can set the location for these task output logs in the
suite.rc file; the default is,
\begin{lstlisting}
# SUITE.RC
job submission log directory = $HOME/CylcJobLogs/$CYLC_SUITE_GROUP/$CYLC_SUITE_NAME
\end{lstlisting}

How the stdout and stderr streams are directed into these files depends
on the job submission method. The \lstinline=background= method just uses
appropriate output redirection on the command line. The
\lstinline=loadleveler= method writes appropriate directives to the job
script that is submitted to loadleveler.

Cylc obviously has no control over the stdout and stderr output from
tasks that do their own internal output management (e.g.\ tasks 
that resubmit sub-jobs and direct the output thereof to other files). 
For less internally complex tasks, however, these job logs will capture
all stdout and stderr for your tasks, and {\em they can be viewed
updating in real time in the suite control GUI}. 

\subsection{Defining New Job Submission Methods}

Defining a new job submission method requires some minimal amount of
Python programming.  You can derive (in the sense of object oriented
programming inheritance) new methods from one of the existing ones, or
directly from cylc's job submission base class,
\begin{lstlisting}
$CYLC_DIR/src/job-submission/job_submit.py
\end{lstlisting}
using the existing methods as examples. Most often this should 
merely be a matter of defining the command line used to execute the
aforementioned job scripts, using the provided stdout and stderr file
paths appropriately. For example, here is the entire class code for 
the \lstinline=background= method:

\lstset{language=Python}

\begin{lstlisting}
#!/usr/bin/env python

from job_submit import job_submit

class background( job_submit ):
    """
Run the job script directly in a background shell. 
    """
    def construct_jobfile_submission_command( self ):
        # stdin redirection allows background execution on remote hosts
        self.command = self.jobfile_path + " </dev/null" + \
                " 1> " + self.stdout_file + " 2> " + self.stderr_file + " &"
# EOF
\end{lstlisting}

Here is the \lstinline=at_now= method:

\begin{lstlisting}
#!/usr/bin/env python

from job_submit import job_submit

class at_now( job_submit ):
    """
Submit the job script to the 'at' scheduler, to run 'now'.
    """
    def construct_jobfile_submission_command( self ):
        self.command = 'at now <<EOF\n' + self.jobfile_path + \
                ' 1> ' + self.stdout_file + ' 2> ' + self.stderr_file + '\nEOF'
# EOF
\end{lstlisting}

Finally, even the \lstinline=loadleveler= method is quite simple:

\begin{lstlisting}
#!/usr/bin/env python

from job_submit import job_submit

class loadleveler( job_submit ):
    """
Minimalist loadleveler job submission.
    """
    def set_directives( self ):
        self.directive_prefix = "# @ "
        self.final_directive  = "# @ queue"

        defaults = {}
        defaults[ 'job_name' ] = self.task_id
        defaults[ 'output'   ] = self.stdout_file
        defaults[ 'error'    ] = self.stderr_file

        defaults[ 'shell'    ] = '/bin/ksh'

        # in case the user wants to override the above defaults:
        for d in self.directives:
            defaults[ d ] = self.directives[ d ]
        self.directives = defaults

    def construct_jobfile_submission_command( self ):
        self.command = 'llsubmit ' + self.jobfile_path
# EOF
\end{lstlisting}

To use your new method, save it in a source file with the same name
as the job submission class (see examples above), install it in the cylc
source tree,
\begin{lstlisting}
$CYLC_DIR/src/job-submission/MyNewJobSubmitMethod.py
\end{lstlisting}
and, in the spec file \lstinline=$CYLC_DIR/conf/suiterc.spec=, 
add its name to the list of allowed values for the 
suite.rc {\em job submission method} configuration items at suite level
and in the tasks section.

%\pagebreak



\section{Getting More Information}
\label{RunningCylcSuites}

Some of the following topics are yet to be properly documented in the
User Guide. For the moment, see cylc command line help (which is
comprehensive, and is included verbatim in Section~\ref{CommandReference});
the suite.rc reference
(Section~\ref{SuiteRCReference}); the gcylc help menus; and the examples
in this document (particularly the {\em Quick Start Guide},
Section~\ref{QuickStartGuide}). 

\begin{myitemize}
    \item the difference between cold-, warm-, raw-, and re-starting, a suite
        (see \lstinline=cylc run help=)
    \item running single tasks outside or inside suites
        (see \lstinline=cylc insert help= and \lstinline=cylc submit help=)
    \item intervening in suites, e.g.\ stopping, removing, inserting tasks; 
        (see \lstinline=cylc control help=)
    \item interrogating suites and tasks 
        (\lstinline=cylc info help=, \lstinline=cylc show help=,
        and \lstinline=cylc discovery help=)
    \item where to look for output - suite log, suite stdout/stderr, task stdout/stderr
        (this is documented in the Quick Start Guide)
    \item understanding cylc suite evolution, particularly in catch up operation
        (the {\em Quick Start Guide} will also help here, along 
        with the cylc example suites, and running your real suites in
        simulation mode)

    \item the cylc lockserver 
        (lockserver startup is documented in the {\em Quick Start
        Guide}; see also \lstinline=cylc lockserver help= and
        \lstinline=cylc lockclient help=)

    \item suite security - use of secure passphrases (this is
        trivial to configure, see documentation of the {\em use secure
        passphrase} configuration item in the {\em Suite.rc Reference},
        Appendix~\ref{SuiteRCReference})
    \item automatic state dump backups, named pre-intervention state dumps
        (mentioned in the {\em Quick Start Guide}; watch the suite log
        after intervening in a suite)
    \item centralized alerting and timeouts
        (see documentation of {\em task event hooks} in the {\em Suite.rc
        Reference}, Appendix~\ref{SuiteRCReference})

    \item recursive purge - this is a powerful suite intervention, but 
        you need to understand how it works before using it.
        See \lstinline=cylc purge help= for details.

\end{myitemize}

\subsection{Advanced Topics}

\begin{myitemize}
    \item spin-up processes via temporary tasks and adding prerequisites
        on-the-fly
    \item how to recover from certain kinds of task failure
    \item instant simulation mode clones of a running suite
    \item fuzzy prerequisites - triggering of the {\em most recent available},
        within limits, instance of an upstream task
    \item asynchronous tasks (no cycle time) - for running a tree of
        tasks initiated by a random event such as a satellite pass. 
    \item subsuites - running another suite inside a task:
\begin{lstlisting}
[tasks]
    [[foo]]
        command = "cylc run SUITE $CYCLE_TIME --until=$CYCLE_TIME"
\end{lstlisting}
\end{myitemize}

%\pagebreak

\section{Suite Design Principles}
\label{SuiteDesignPrinciples}

%Simplicity, flexibility, efficiency, and portability of cylc suites.

\subsection{Make Fine-Grained Suites} 
\label{Granularity}

A suite can contain a small number of large, internally complex tasks; a
large number of small, simple tasks; or anything in between. Cylc can
easily handle a large number of tasks, however, so there are definite
advantages to fine-graining:

\begin{myitemize}
    \item a more modular and transparent suite.

    \item better functional parallelism (multiple tasks running
        at the same time).

    \item faster debugging and failure recovery: rerun just the tasks(s)
        that failed. 

    \item code reuse: similar tasks can often call the same script or
        command with differing task-specific input parameters
        (consider tasks that move files around, for example).

\end{myitemize}

\subsection{Use Include-Files For Groups Of Related Tasks}

Suite.rc include-files can be used just to help organise tasks into
convenient groups in very large suites (and with \lstinline=cylc edit= 
you can edit a temporarily inlined file to get a global view). 
But they are most useful for handling the repetitive definition of
groups of similar tasks, because the same inclusion can be used multiple
times in the same suite.rc file.  See {\em Include Files}
(Section~\ref{IncludeFiles}).


\subsection{Make Tasks Rerunnable}

It should be possible to rerun a task by simply resubmitting it for the
same cycle time. In other words, failure at any point during execution
of a task should not render a rerun impossible by corrupting the state
of some internal-use file, or whatever. It's difficult to overstate the
usefulness of being able to rerun the same task multiple times,
either outside of the suite with \lstinline=cylc submit=, or by
retriggering it within the running suite, when debugging a problem.

\subsection{Make Models Rerunnable} 

If a warm-cycled model simply overwrites its restart files in each
run, the only cycle that can subsequently run is the next one. This
is dangerous because if, accidentally or otherwise, the task runs for the
wrong cycle time, its restart files will be corrupted such that the
correct cycle can no longer run (probably necessitating a cold start).
Instead, consider organising restart files by cycle time, through a file
or directory naming convention, and keep them in a simple rolling
archive (cylc's filename templating and housekeeping
utilities can easily do this for you). Then, given availability of 
any external inputs, you can easily rerun the task for any cycle still
in the restart archive.

\subsection{Limit Previous-Instance Dependence} 
\label{LimitPID}

Cylc does not require that successive instances of the same task run 
sequentially. In order to task advantage of this and achieve maximum
functional parallelism whenever the opportunity arises (usually when 
catching up from a delay) you should ensure that tasks that in
principle do not depend on their own previous instances (the vast
majority of tasks in most suites, in fact) do not do so in practice. In
other words, they should be able to run as soon as their prerequisites
are satisfied regardless of whether or not their predecessors have
finished yet.  This generally just means ensuring that all file I/O
contains the generating task's cycle time in the file or directory name
so that there is no interference between successive instances. If this
is difficult to achieve in particular cases, however, you can declare
the offending tasks to be {\em sequential}.

% MAYBE SHOULD INCLUDE THE FOLLOWING HERE:
%Warm-cycled forecast models {\em do} depend on their own previous
%instances (through their ``model background'' restart prerequisites).
%These can be made to run sequentially (i.e.\ with maximal previous
%instance dependence) but you can have cylc suite launch the next model,
%assuming other prerequisites are satisfied, as soon as the previous one
%has completed its restart prerequisites (minimal previous instance
%dependence, maximal throughput).

\subsection{Put Task Cycle Time In All Output File Paths}
\label{PutCycleTimeinIO}

Having all filenames, or perhaps the names of their containing
directories, stamped with the cycle time of the generating task greatly
aids in managing suite disk usage, both for archiving and cleanup. It
also enables the aforementioned task rerunnability recommendation by avoiding
overwrite of important files from one cycle to the next. Cylc has 
powerful utilities for cycle time offset based filename templating and
housekeeping.

\subsubsection{Use Cylc's Cycle Time Filename Template Utility}

The command line utility program \lstinline=cylc template=
determines filenames based on a template string containing
YYYYMMDDHH (or variations thereof) by substituting the
current cycle time, or some offset from it, into the template.
This can be used in the suite.rc environment sections, or in
task implementation scripts if necessary, to instantly generate cycle
time appropriate filenames for any purpose in the suite.

See \lstinline=cylc util template help= for more information.

\subsection{How To Manage Input/Output File Dependencies}
\label{HandlingDependencies}

Dependencies between tasks usually, though not always, take the form of
files generated by one task that are used by other tasks. It is possible
to manage these files across a suite without hard wiring I/O locations 
and therefore comprising suite flexibility and portability.

\begin{myitemize}

\item {\bf Use A Common I/O Workspace}

For small suites you may be able to have all tasks read and write from a
common workspace, thereby avoiding the need to move common files around.
You should be able to define the workspace location once in the suite.rc
file rather than hard wiring it into the task implementations.

\item {\bf Add Connector Tasks To The Suite} 

Tasks can be added to a suite to move files from A's output directory to
B's input directory, and so on.  These connector tasks may all be able
to call the same file transfer script or command, with differing input
parameters defined in the suite.rc file. 

\item {\bf Dynamic Configuration Of I/O Paths}

Whether or not your suite uses a single common workspace, passing common
I/O paths to tasks via variables defined once in the suite.rc file should
allow you to avoid using connector tasks at all, except where it is
necessary to transfer files between machines, or similar. 

\end{myitemize}

\subsection{Use Generic Task Scripts}

If your suite contains multiple logically distinct tasks that actually
have similar functionality (e.g.\ for moving files around, or for 
generating similar products from the output of several similar models)
have the corresponding cylc tasks all call the same command, script, or
executable - just provide different input parameters
via the task command scripting and/or execution environment, in the
suite.rc file.


\subsection{Make Suites Portable}

If every task in a suite is configured to put its output under
\lstinline=$HOME= (i.e.\ the environment variable, literally, not the
explicit path to your home directory; and similarly for temporary
directories, etc.) then other users will be able to copy the suite and
run it immediately, after merely ensuring that any external input files
are in the right place.

For the ultimate in portability, construct suites in which all task I/O
paths are dynamically configured to be user and suite (registration)
specific, e.g.
\begin{lstlisting}
$HOME/output/$CYLC_SUITE_GROUP/$CYLC_SUITE_NAME/
\end{lstlisting}
(these variables are automatically exported to the task execution
environment by cylc - see {\em Task Execution Environment},
Section~\ref{TaskExecutionEnvironment}). Then you can run multiple
instances of the suite
at once (even under the same user account) without changing anything,
and they will not interfere with each other.

{\em You can test changes to a portable suite safely by making a quick copy
of it in a temporary directory, then modifying and running the test copy 
without fear of corrupting the output directories, suite logs, and 
suite state, of the original.} 


\subsection{Make Tasks As Self-Contained As Possible}

Where possible, no task should rely on the action of another task,
except for the prerequisites embodied in the suite dependency graph that
it has no choice but to depend on. If this rule is followed, your suite
will be as flexible as possible in terms of being able to run single
tasks, or subsets of the suite, whilst debugging or developing new
features.\footnote{The \lstinline=cylc submit= command runs a single
task exactly as its suite would, in terms of both job submission method and
execution environment.}  For example, every task should create its own
output directories if they do not already exist, instead of assuming
their existence due to the action of some another task; then you will be
able to run single tasks without having to manually create output
directories first. 

\begin{lstlisting}
# manual task scripting:
  # 1/ create $OUTDIR if it doesn't already exist:
  mkdir -p $OUTDIR
  # 2/ create the parent directory of $OUTFILE if it doesn't exist:
  mkdir -p $( dirname $OUTFILE )

# OR using the cylc checkvars utility:
  # 1/ check vars are defined, and create directories if necessary:
  cylc util checkvars -c OUTDIR1 OUTDIR2 #...
  # 2/ check vars are defined, and create parent dirs if necessary:
  cylc util checkvars -p OUTFILE1 OUTFILE2 #...
\end{lstlisting}

\subsection{Make Suites As Self-Contained As Possible}

The only compulsory content of a cylc suite definition directory is the
suite.rc file (and you'll almost certainly have a suite
\lstinline=bin= sub-directory too). However, you can store whatever you
like in a suite definition directory;\footnote{If you copy a suite using
cylc commands or gcylc, the entire suite definition directory
will be copied.} other files there will be ignored by cylc but
suite tasks can access them via the
\lstinline=$CYLC_SUITE_DIR= variable that cylc automatically 
exports into the task execution environment. Disk space is cheap - if
all programs, ancillary files, control files (etc.) required by the
suite are stored in the suite
definition directory instead of having the suite reference external
build directories (etc.), you can turn the directory into a revision
control repository and be virtually assured of the ability to exactly
reproduce earlier versions as required, regardless of suite
complexity.

\subsection{Orderly Product Generation?}
\label{OrderlyProductGeneration}

Correct scheduling is not equivalent to ``orderly generation of products
by cycle time''.  Under cylc, a product generation task will trigger as
soon as its prerequisites are satisfied (i.e.\ when its input files are
ready, generally) regardless of whether other tasks with the same cycle
time have finished or have yet to run. If your product delivery or
presentation system demands that all products for one cycle time are
uploaded (or whatever) before any from the next cycle, then be aware
that this may be quite inefficient if your suite is ever faced with
catching up from a significant delay or running over historical data.

If you must, however, you can introduce artificial dependencies into
your suite to ensure that the final products never arrive out of
sequence.  One way of doing this would be to have a final ``product
upload'' task that depends on completion of all the real product
generation tasks at the same cycle time, and then declare it to be
sequential so that successive instances cannot run out
of sequence, or in parallel, even if the opportunity arises.

\subsection{Clock-triggered Tasks Should Wait On External Data}

All tasks in a cylc suite know their own private cycle time, but most
don't care about the wall clock time - they just run when their
prerequisites are satisfied. The exception to this is {\em
clock-triggered} tasks, which wait on a wall clock time expressed as an
offset from their own cycle time, in addition to any other
prerequisites. The usual purpose of these tasks is to retrieve real time
data from the external world, triggering at roughly the expected time of
availability of the data. Triggering the task at the right time is up to
cylc, but the task itself should go into a check-and-wait loop in case
the data is delayed; only on successful detection or retrieval should
the task report success and then exit (or perhaps report failure and
then exit if the data has not arrived by some cutoff time). 

\subsection{Do Not Treat Real Time Operation As Special} 

Cylc suites, without modification, can handle real time and delayed
operation equally well.

In real time operation clock-triggered tasks constrain the
behaviour of the whole suite, or at least of all tasks 
downstream of them in the dependency graph.

In delayed operation (due to an actual delay in an operational suite or
because you're running an historical case study) clock-triggered tasks
will not constrain the suite at all, and cylc's multi-cycling abilities
come to the fore, because their trigger times have already passed. 
But if a clock-triggered task happens to catch up to the wall clock, it
will automatically wait again. In this way a cylc suite naturally
and seamlessly transitions between delayed and real time operation 
as required.

\pagebreak

\appendix
\section{Suite.rc Reference}
\label{SuiteRCReference}

This section documents all legal entries in a suite.rc file. The
information is extracted from the specification file
\lstinline=$CYLC_DIR/conf/suiterc.spec= during document processing, so
that the User Guide is automatically kept up to date.  Section 
headings are generated with the same nesting structure as the file
itself to make it easy to get at the documentation you need by clicking on 
hyperlinks in the PDF document contents page.

Most suites will only need a few of these settings - many configuration
items have default values that should be sufficient, some are probably
only needed
for critical operational suites (e.g.\ secure passphrases and task event
hooks), and some are primarily used for cylc development (e.g.\ simulation
mode configuration). In general your suite.rc files shouldn't be a 
lot more complicated than those of the cylc example suites.

%\subsection{Overview}
%
%Details of suite.rc syntax are described in
%Section~\ref{SuiteRCFile}. For this section it suffices to say that
%every entry in the file is of the form:
%\begin{lstlisting}
%item = value
%\end{lstlisting}
%where \lstinline=item= may be a phrase containing spaces, and
%\lstinline=value= may be an integer, float, boolean (True/False),
%string, multiline string, or a comma-separated list of any of the
%%former.  suite.rc files are validated against
%\lstinline=$CYLC_DIR/conf/suiterc.spec=, which defines what
%items are allowed, and places constraints on what values are legal for
%each item.

\input{suiterc.spec.tex}

%\pagebreak

\section{Command Reference}
\label{CommandReference}

%This section is auto-generated from the self-documenting command set.
  
%\lstset{ basicstyle=\color{basic}\footnotesize\ttfamily }
\lstset{language=usage}
\input{commands.tex}


\section{The Graph-Based Suite Control GUI}
\label{TheGraphBasedSuiteControlGUI}

The graph-based suite control GUI has the advantage that it shows
the structure of a suite very clearly as it evolves. It works 
remarkably well even for very large suites, on the order of one hundred
tasks or more {\em but} on the downside, the graphviz engine does a new
global optimization every time the graph changes, so the layout is often
not very stable. This may or may not be a solvable problem - it seems
likely that making continual incremental changes to an existing graph
without redoing the global layout would inevitably result in some kind
of horrible mess.

The following features of the graph-based control GUI go a long way 
toward mitigating the changing layout problem:

\begin{myitemize}
    \item The disconnect button can be used to temporarily prevent the
        graph from changing as the content of the suite changes (and
        in real time operation suites evolve quite slowly anyway)
    \item Right-click on a task and choose the ``Focus'' option to restrict
        the graph display to that task's cycle time. Anything interesting
        happening in other cycles will show up as disconnected
        rectangular nodes to the right of the graph (and you can click
        on those to intantly refocus to their cycles).
    \item Task filtering is the ultimate quick route to temporarily focusing
        on just the tasks you're interested in (but this will 
        destroy the graph structure, to state the obvious).
\end{myitemize}

In future cylc releases we plan to keep the graph centered, after layout
changes, on the most recently clicked-on task.


\section{Simulation Mode} 
\label{SimulationMode}

If you start a suite in simulation mode (a command line option for the cold-,
warm-, raw-, and re-start commands, and a checkbutton in the gcylc suite
start panel) then cylc will run on an accelerated clock and submit dummy
programs instead of the real tasks. These masquerade as the real tasks
by reporting the correct outputs complete after a short interval,
reporting success, and then exiting. This is essentially
indistinguishable, to cylc, from real operation. Simulation mode was, and
remains, an important aid to cylc development because it allows
testing of every aspect of scheduling without having to run real
tasks in real time. Prior to cylc-3 it was also a useful aid to suite
development - a simulation run would quickly identify any mismatch between
the user-defined prerequisites and outputs across the suite, so you
could get the scheduling right without running the real tasks. Post
cylc-3.0 this is less important because task prerequisites and outputs
are implicitly defined by the dependency graph and, short of a bug in
cylc, the suite will run according to the graph.

\subsection{Clock Rate and Offset}

Simulation mode suites run on an accelerated clock so that you can test
things very quickly. You can set the clock rate and offset with respect
to the initial cycle time with options to the \lstinline=cylc run=
command. An offset of 10 hours, say, means that the simulation mode clock
starts at 10 hours prior to the suite's initial cycle time.  You can
thus simulate the behaviour of the suite as it catches up from a delay
and transitions to real time operation.  By default, the clock runs at a
rate of 10 seconds real time to 1 hour suite time, and with an initial
offset of 10 hours. 

\subsection{Switching A Suite Between Simulation And Live Modes?}

The scheduler mode (simulation or live) is recorded in the suite state
dump file. {\em Cylc will not let you restart a simulation mode suite in
live, or a live mode suite in simulation mode} - any attempt to do the 
former must certainly be a mistake, and doing the latter, while
feasible, would corrupt your live suite state dump and turn it over to
simulation mode. Note, however, that if you really want to run the
current state of a live suite forward in simulation mode,
all you need to do is this:
\begin{myenumerate}
    \item back up the live state dump (or take note of the filename
        of the relevant automatic dump when you do the final suite
        shutdown intervention).
    \item edit the mode line in the state dump file, and restart the
        suite in simulation mode.
    \item later, restart the live suite from the pre simulation mode
        state dump backup 
\end{myenumerate}

{\em Cylc can also create an instant dummy mode clone of the current
state of any running or stopped suite, but this ``practice mode'' has
been disabled in the current release pending testing.}

%\subsubsection{Practice Mode}
%
%Practice mode allows quick and easy testing of potentially complex
%suite interventions, with complete safety.
%
%\begin{lstlisting}
%cylc restart --practice examples:CUG1
%\end{lstlisting}
%
%This will start a simulation mode clone of an existing suite from the
%current state of that suite (which may be paused, still running, or
%halted), but using different state and log files so that the original
%suite will not be corrupted by the clone.
%
%{\em At startup in practice mode, failed tasks are not reset to waiting}
%because the whole point of practice mode is to ``practice'' how to
%recover from failures.
%
%Note that other cylc commands for monitoring or interacting with the
%suite must also use the \lstinline=--practice= option in order to
%target the practice suite and not the real one. Be sure to set
%\lstinline=cylc lock= on the original suite first, to avoid
%accidentally messing with it (even if you do screw up, however, cylc's
%automatic pre-intervention state dumps will save you!).
%
%
%\subsubsection{Roll Your Own Practice Mode}
%
%A less automated way to ``practice'' on a copy of an existing suite
%that starts up from the current (or previous) state of that suite, 
%\lstinline=cylc run --practice= is this:
%
%\begin{myitemize}
%    \item register your suite again under a different name. This allows
%        you to run a simulation mode copy of the same suite without
%        interfering with the original suite (it also allows you to run
%        a copy of the live mode suite without interference, but only if
%        the real suite tasks are configured to use the registered
%        suite name in all important input and output filenames and/or
%        directory paths - see {\em Command Reference} Section~\ref{register}).
%
%    \item start up the newly registered suite in simulation mode using:
%        \begin{lstlisting}
%cylc restart --simulation-mode SUITE PATH
%        \end{lstlisting}
%        where PATH is a state dump file from the original suite. The
%        absolute path is required here because the default state
%        dump location depends on the registered suite name (so that
%        different suites don't interfere with each other's state
%        dumps).
%
%\end{myitemize}
%

        

%\pagebreak

%\section{Network Issues}
%
%Cylc can control tasks on a distributed system (multiple hosts).  If you
%do have a distributed suite, in any or all of these ways, be aware of
%the following issues: 
%
%\begin{myitemize}
%
%    \item In addition to the cylc host, cylc must be installed on all
%        task hosts; and the remote task scripts must
%        themselves be installed on their host machines.  Refer to {\em
%        Running Tasks On A Remote Host}
%        (Section~\ref{RunningTasksOnARemoteHost}) for more on this.
%
%    \item Pyro must be installed on every host used by the suite.
%         Ideally all relevant machines should have the same version of
%         Pyro, but you can easily check for Pyro cross-version
%         compatibility by attempting to run one of the cylc example
%         system.
%        
%\end{myitemize}
%
%Other notes relevant to the last point above: the \lstinline=--host=
%cylc command option defaults to Python \lstinline=socket.getfqdn()=,
%which retrieves the fully qualified domain name of the local host
%if possible.  But \lstinline=/etc/hosts= may cause this to return
%just the hostname, which locally may resolve to the local-only IP
%address that is not accessible on the network.  Short of reconfiguring
%the hosts file, you may be able to workaround these problems by:
%
%\begin{myitemize}
%
%    \item and, get cylc to configure the Pyro daemon 
%        with \lstinline@Pyro.config.PYRO_DNS_URI = True@ 
%        
%    \item and, use the \lstinline=--host= cylc command option where
%        required.
%
%\end{myitemize}

\section{Cylc Development History}
\subsection{Pre-3.0}

Early versions of cylc were focused on developing and testing the new 
scheduling algorithm, and the suite design interface at the time was
essentially the quickest route to that end. A suite was a collection
of ``task definition files'' that encoded the prerequisites and outputs
of each task in a direct reflection of cylc's internal task proxies. 
This way of defining suites exposed cylc's self-organising nature to the
user, and it did have some nice properties. For instance a group of
tasks could be transferred directly from one suite to another by simply
copying the taskdef files over (and checking that prerequisite and
output messages were consistent with the new suite). However, ensuring
consistency of prerequisites and outputs across a large suite could be
tedious; a few edge cases associated with suite startup and forecast
model restart dependencies were, arguably, difficult to understand; and
the global structure of a suite was not readily apparent until run time
(although to counter this cylc 2.x could generate run-time resolved
dependency graphs very quickly in simulation mode).

\subsection{Post-3.0}

Version 3.0 implemented an entirely new suite design interface in which
one defines the suite dependency graph, execution environment, and
command scripting and for each task, in a single structured, validated,
config file - the suite.rc file.  This {\em really} makes suite
structure apparent at a glance, and task prerequisites and outputs (and
some other important parameters besides) no longer need to be specified
by the user because they are implied by the graph.



\section{Pyro} 
\label{Pyro}

Pyro (Python Remote Objects) is a widely used open source objected
oriented Remote Procedure Call technology, see {\em
http://pyro.sourceforge.net}.

Earlier versions of cylc used the Pyro Nameserver to handle marshalling
of communication between client programs (tasks, commands, viewers,
etc.) and their target suites. This worked well, but in principle it
provided a route for one suite or user on the subnet to bring down 
all running suites by killing the nameserver. Consequently cylc now
uses Pyro simply as a lightweight object oriented wrapper for
direct network socket communication between client programs and their
target suites - all suites are thus entirely isolated from one another. 

%\section{Known Limitations}
%
%\begin{myitemize}
%    \item {\em The minimum cycle time granularity for a task is
%        currently one hour}.
%
%Note that this is only loosely connected to when a task actually runs,
%and then only in real time operation: clock-triggered tasks trigger at
%some interval beyond their nominal cycle time, which in real time
%operation will be at most hourly for a given task. Aside from this, tasks
%can run as soon as their prerequisites are satisfied regardless of their
%nominal cycle time. This minimum granularity could be extended to
%minutes and seconds if necessary.  
%
%    \item {\em Every task must run at least once per day} (of cycle
%        time, not real time, although the first implies the second in
%        real time operation). 
%
%This could be extended to allow less frequent tasks, e.g.\ once per
%week, if required. 
%
%\end{myitemize}

%\section{Miscellaneous Notes}
%\label{MiscellaneousNotes}
%
%%\subsection{Cycle Dependent Prerequisites}
%%It may be better to split a task into two (or more) than use this 
%%capability. NOT FOR FORECAST MODELS WITH RESTART OUTPUTS!

%\subsection{Catching Up}
%labelsubsection{CatchingUp}
%
%The state of being ``caught up'' or not is a property of individual
%tasks, not the whole suite, and additionally it should only matter to
%external contact tasks, i.e.\ those that wait on external data that is
%available at a wall clock time of T (task cycle time) + o (some offset
%insterval). Where this matters an external task can detect whether or
%not it has caught up (and signal this to its proxy object in cylc) by
%comparing its cycle time (and offset) to the wall clock time.  


\section{Acknowledgements}

Bernard Miville and Phil Andrews (NIWA), and David Matthews (Met
Office UK), for discussion, bug finding, and many suggestions that have
improved cylc's usability and functionality.

\section{GNU GENERAL PUBLIC LICENSE v3.0}
\input{gpl-3.0}



%\subsection{Understanding Suite Evolution}
%\label{UnderstandingSuiteEvolution}
%
%On a cold start all tasks (including one off tasks) in the sytem will be
%instantiated at the initial cycle time, or at the next subsequent valid
%cycle time for the task. Any tasks that have no prerequisites (and, if
%they are contact tasks, have reached their trigger time) will submit to
%run immediately. Any cycling (i.e.\ non one off) tasks that have no
%prerequisites (and, if they are contact tasks, have reached their
%trigger time) will rapidly spawn ahead until stopped by the suite's
%runahead limit (observe task X in the User Guide example suite).
%Thereafter, each task will, of its own accord, submit to run as soon as
%its prerequisites have been satisfied by other tasks already running or
%succeeded in the suite (and trigger time etc.).  Each task spawns a
%successor at a point in its lifecycle that depends on its type: tied
%tasks spawn has soon as their restart prerequisites have been completed,
%and free tasks spawn at the instant they start running.  Once a task
%exists it is free to run as soon as its prerequisites are satisfied,
%thus successive instances of a free task can run entirely in parallel,
%and successive instances of a tied task can overlap if the opportunity
%arises (other prerequisites allowing).

%\subsection{Automatic State Dumps}
%\label{AutomaticStateDumps}
%
%Cylc updates its configured state dump file (e.g.\
%\lstinline=$HOME/cylc-state/state=) every time the state of a task
%changes. Previous states are maintained in a rolling archive 
%(length specified in the {\em suite.rc} file):
%
%\begin{lstlisting}
%nwp_oper> ls .cylc/state/SUITE/
%state       # current state
%state-1     # most recent previous state
%state-2     # next most recent previous state
%...
%state-N     # oldest state dump; will be deleted at next update
%\end{lstlisting}
%
%In addition, immediately prior to any system intervention a special
%uniquely named state dump file is created and logged, e.g.:
%
%\begin{lstlisting}
%2010/03/30 14:54:29 WARNING main - pre-purge state dump: state.2010:3:30:14:54:29
%\end{lstlisting}
%
%If you accidentally intervene wrongly in a suite, just shut it down
%and restart from the pre-intervention state dump:
%
%\begin{lstlisting}
%cylc restart SUITE state.2010:3:30:14:54:29
%\end{lstlisting}

%\subsection{Suite Log Files}
%\label{SuiteLogFiles}
%
%Earlier versions of cylc created a main suite log file and a
%task-specific log for every task. However, because when all logged
%events were made to percolate up to the main log the task-specific logs
%became superfluous. Instead, cylc provides facilities for filtering the
%main log for task-specific messages (or you can just use
%\lstinline=grep= for this purpose).
%
%\lstset{language=,
%basicstyle=\color{basic}\scriptsize\ttfamily,
%}
%\begin{lstlisting}
%$ tail $HOME/cylc-logs/intro/log
%2010/03/28 00:33:50 INFO main.F - [2010010312] disconnected (spent; general)
%2010/03/28 00:33:52 INFO main.C - [2010010400] storm surge fields ready for 2010010400
%2010/03/28 00:33:52 INFO main.A - [2010010412] surface wind fields ready for 2010010412
%2010/03/28 00:33:52 INFO main.C - [2010010400] C%2010010400 completed
%2010/03/28 00:33:52 INFO main.C - [2010010400] C%2010010400 succeeded
%2010/03/28 00:33:52 INFO main.A - [2010010412] surface pressure field ready for 2010010412
%2010/03/28 00:33:52 INFO main.A - [2010010412] level forecast fields ready for 2010010412
%2010/03/28 00:33:53 INFO main.A - [2010010412] A%2010010412 completed
%2010/03/28 00:33:53 INFO main.A - [2010010412] A%2010010412 succeeded
%2010/03/28 00:33:53 CRITICAL main - ALL RUNNING TASKS SUCCEEDED
%\end{lstlisting}
%
%\lstset{language=,
%basicstyle=\color{basic}\footnotesize\ttfamily,
%}

%Each entry shows the time of logging, the name and cycle time of the
%reporting task (in square brackets), and the logged message.
%
%In simulation mode, the logged time is the simulation mode accelerated clock time, not 
%real time.
%
%Existing log files are automatically rotated at start up and,
%individually, when they reach a size of 10 MB.  This maximum file 
%size should be configurable, but it is currently hardwired in
%\lstinline=$CYLC_DIRsrc/pimp_my_logger.py=.

%\subsection{Diagnosing A Stalled Suite}
%\label{DiagnosingAStalledSuite}
%
%In certain situations a suite may appear to be ``stuck'', i.e.\ no
%tasks are running and nothing appears to be happening. There are several 
%possible reasons for this (it does not necessarily indicate a problem!):
%
%\begin{myitemize}
%    \item In {\em normal real time operation}, when all running tasks
%        have finished for the most recent cycle, nothing will happen
%        until the one or more contact tasks in the suite trigger at the
%        start of the next cycle. \lstinline=cylc show= tells if a
%        contact task has yet to reach its trigger time.
%
%    \item if every task in the suite has one or more unsatisfied
%        prerequisites, the suite will be stalled. This could happen,
%        for example, if you start a suite that contains tied (forecast
%        model) tasks without the corresponding one off cold start tasks to
%        satisfy their initial restart prerequisites.
%
%\end{myitemize}
%
%The following problems will eventually cause a suite to get stuck at
%the {\em runahead limit} (which by default is 24 hours: i.e.\ the
%fastest task in the suite is only allowed to get 24 hours ahead of the
%slowest) because cylc does not automatically remove failed tasks from
%the system.  Operational suites should have automated means of
%alerting the operators to any failure that occurs, but in the
%unlikely event that the failure is not noticed until the system stalls
%at the runahead limit, then to get things moving again the operator must
%either remove the failed task or reset (and thereby rerun) it after
%fixing the problem that cause the failure.
%
%\begin{myitemize}
%    \item If the system operator, perhaps in a post-task-failure
%    intervention, kills some tasks that are required to satisfy the
%    prerequisites of other tasks that still exist in the system, then 
%    the suite will eventually stall as a result of these tasks being
%    unable to run. Solution: insert tasks (possibly one off cold start
%    tasks) to get the suite running again.
%
%    \item If some task in the suite has a cycling interval long than
%        the runahead limit, the suite will stall (e.g.\ if
%    you have a task that runs 24-hourly at 00Z, but set the runahead
%    limit to just 12 hours). This could also happen if you purge enough
%    cycles that the difference between the pre- and post-purge tasks
%    is greater than the runahead limit. Solution: ensure your runahead
%    limit is large enough to span these gaps.
%
%    \item If a failed task has not yet been removed or reset by the
%    system operator it will eventually stall the suite. Solution:
%    Fix, or otherwise deal with, failed tasks as quickly as possible.
%
%    \item If through a suite design error error, a task exists that
%        cannot get its prerequisites satisfied by any other task in the
%        suite, that task will never run and will eventually cause the
%        suite to stall.  Solution: test the suite in simulation mode to 
%        check that all prerequisites and outputs, suite-wide, are 
%        compatible.
%
%    \item If a misconfigured external task does not report an output
%        that it is supposed to (i.e.\ as registered in its task proxy
%        definition file), then its task proxy will not record that 
%        output as complete and cylc will set it to the 'failed' state
%        when it finishes without completing a registered output. A
%        failed task will eventually stall the suite, as explained above, 
%        if it is not fixed and re-run, or removed from the suite.
%        Solution: ensure all external tasks report their outputs
%        correctly.
%
%\end{myitemize}
%
%To confirm that the runahead limit is causing a stall, you can use 
%\lstinline=cylc verbosity= to set the debug logging level: any task
%that is not spawning a successor only because it has exceeded the
%runahead limit will report that to the log.
%
%
%\subsection{Failure Recovery Scenarios}
%\label{FailureRecoveryScenarios}
%
%\begin{myitemize}
%    \item {\em One forecast cycle runs into the next, after a delay in
%        operations}. This is never a problem for cylc; every task runs
%        as soon as it can run, regardless of forecast cycle, and any
%        task that can't run before it's predecessor has finished will
%        wait.
%
%    \item {\em A delayed parallel trial or case study catches up to real
%        time operation}. This is no problem for cylc; any cylc suite
%        will seamlessly transition in and out of ``normal real time
%        operation'' (distinct cycles triggered by the wall clock) as needed.
%
%    \item {\em An external task fails, but can be fixed}. For example, a
%        forecast model aborts trying to read a corrupted data file that
%        can be regenerated correctly. The failed task will be noted by
%        cylc, and its downstream dependants will not be able to run,
%        but other tasks will carry on as normal while you address the
%        problem. When fixed, use `cylc reset' to get the failed task to
%        run again, after which it and its downstream dependants will
%        catch up to the rest of the suite as quickly as possible.
%
%    \item {\em An important external task fails, but cannot be fixed.}
%        In this case, if the task has a lot of downstream dependants,
%        you will presumably need omit one or more cycles of the affected
%        tasks, and cold start their part of the suite at a the earliest
%        possible subsequent cycle.  To do this, insert the relevant cold
%        start task, or task group, at the later cycle, then purge the
%        failed task and everything that depends on it (and on them, and
%        so on) down to the cold start time.  Other downstream forecast
%        models will be able to pick up immediately so long their most
%        recent previous instance (i.e.\ just before the gap) wrote out
%        sufficient restart outputs to bridge the gap (otherwise they,
%        or perhaps the entire suite, will need to be cold started). 
%
%    \item {\em HELP, I attempted a drastic intervention in a complex
%        suite, using the horrifying purge command, and this time I
%        really screwed the pooch!} Before any operation that alters the
%        sytem state, cylc automatically writes out a special state dump
%        file and reports the filename in the main log. Shut the suite
%        down and restart it from its pre-intervention state (just
%        cut-and-paste the state dump filename from the main log file -
%        the file path is not required because the file will be in the
%        configured suite state dump directory).  Then {\em retry your
%        intervention in practice mode} before doing it for real!
%
%\end{myitemize}
%
%\subsection{Dead Suite Cleanup}
%%\label{DeadSuiteCleanup}
%
%\subsubsection{Normal Shutdown}
%
%Cylc waits for any currently running tasks to finish before shutting
%down cleanly. There will be nothing to clean up. 
%
%\subsubsection{Shutdown NOW or Controlled Abort}
%
%If a critical error of some kind, or use of \lstinline=cylc stop --now=,
%results in an immediate suite shutdown while there are still external
%tasks running, any subsequent cylc messaging calls made by the
%still-running tasks will fail because the parent suite no longer
%exists. Depending on the exact circumstances this may result in some 
%orphaned processes that need to be killed manually.
%
%\subsubsection{Uncontrolled Suite Abort}
%
%(To Do, check: currently no ill effects - maybe sockets (ports) remain
%tied up until they time out?).
%
%
%
%\pagebreak


