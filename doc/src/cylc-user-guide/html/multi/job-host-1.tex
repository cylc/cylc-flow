\section{Remote Job Management}

Managing tasks in a workflow requires more than just job execution: Cylc
performs additional actions with \lstinline=rsync= for file transfer, and
direct execution of \lstinline=cylc= sub-commands over non-interactive
SSH.\footnote{Cylc used to run bare shell expressions over SSH, which required
a bash shell and made whitelisting difficult.}

\subsection{SSH-free Job Management?}

Some sites may want to restrict access to job hosts by whitelisting SSH
connections to allow only \lstinline=rsync= for file transfer, and allowing job
execution only via a local batch system that sees the job hosts.\footnote{A
malicious script could be \lstinline=rsync='d and run from a batch job, but
batch jobs are considered easier to audit.} We are investigating the
feasibility of SSH-free job management when a local batch system is available,
but this is not yet possible unless your suite and job hosts also share a
filesystem, which allows Cylc to treat jobs as entirely local.\footnote{The job ID
must also be valid to query and kill the job via the local batch system. This
is not the case for Slurm, unless the \lstinline=--cluster= option is
explicitly used in job query and kill commands, otherwise the job ID is not
recognized by the local Slurm instance.}

\subsection{SSH-based Job Management}

Cylc does not have persistent agent processes running on job hosts to act on
instructions received over the network\footnote{This would be a more complex
solution, in terms of implementation, administration, and security.} so
instead we execute job management commands directly on job hosts over SSH.
Reasons for this include:
\begin{itemize}
  \item it works equally for batch system and background jobs
  \item SSH is {\em required} for background jobs, and for batch jobs if the
    batch system is not available on the suite host
  \item {\em querying the batch system alone is not sufficient for full job
    polling functionality} because jobs can complete (and then be forgotten by
    the batch system) while the network, suite host, or suite server program is
    down (e.g.\ between suite shutdown and restart)
    \begin{itemize}
      \item to handle this we get the automatic job wrapper code to write
        job messages and exit status to {\em job status files} that are
        interrogated by suite server programs during job polling operations
      \item job status files reside on the job host, so the interrogation
        is done over SSH
    \end{itemize}
  \item job status files also hold batch system name and job ID; this is
    written by the job submit command, and read by job poll and kill commands
    (all over SSH)
\end{itemize}

\subsection{A Concrete Example}

The following suite, registered as \lstinline=suitex=, is used to illustrate
our current SSH-based remote job management. It submits two jobs to a remote,
and a local task views a remote job log then polls and kills the remote jobs.

\lstset{language=suiterc}
\begin{lstlisting}
# suite.rc
[scheduling]
   [[dependencies]]
          graph = "delayer => master & REMOTES"
[runtime]
   [[REMOTES]]
      script = "sleep 30"
       [[[remote]]]
           host = wizard
           owner = hobo
   [[remote-a, remote-b]]
       inherit = REMOTES
   [[delayer]]
      script = "sleep 10"
   [[master]]
       script = """
 sleep 5
 cylc cat-log -m c -f o $CYLC_SUITE_NAME remote-a.1
 sleep 2
 cylc poll $CYLC_SUITE_NAME REMOTES.1
 sleep 2
 cylc kill $CYLC_SUITE_NAME REMOTES.1
 sleep 2
 cylc remove $CYLC_SUITE_NAME REMOTES.1"""
\end{lstlisting}

The {\em delayer} task just separates suite start-up from remote job
submission, for clarity when watching the job host (e.g.\ with
\lstinline=watch -n 1 find ~/cylc-run/suitex=).

Global config specifies the path to the remote Cylc executable, says
to retrieve job logs, and not to use a remote login shell:
\begin{lstlisting}
# global.rc
[hosts]
   [[wizard]]
       cylc executable = /opt/bin/cylc
       retrieve job logs = True
       use login shell = False
\end{lstlisting}

On running the suite, remote job host actions were captured in the transcripts
below by wrapping the \lstinline=ssh=, \lstinline=scp=, and \lstinline=rsync=
executables in scripts that log their command lines before taking action.
